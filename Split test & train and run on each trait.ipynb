{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://billchambers.me/tutorials/2015/01/14/python-nlp-cheatsheet-nltk-scikit-learn.html\n",
    "\n",
    "http://glowingpython.blogspot.de/2013/07/combining-scikit-learn-and-ntlk.html\n",
    "\n",
    "http://www.cs.duke.edu/courses/spring14/compsci290/assignments/lab02.html\n",
    "\n",
    "https://stackoverflow.com/questions/10526579/use-scikit-learn-to-classify-into-multiple-categories\n",
    "\n",
    "https://github.com/anuraagvak/IRE-PersonalityRecognition-Final/blob/master/ire_report.pdf\n",
    "\n",
    "https://github.com/Charudatt89/Personality_Recognition/blob/master/22-9-PersonalityRecognition/Report/Report.pdf\n",
    "\n",
    "http://stackoverflow.com/questions/2148543/how-to-write-a-confusion-matrix-in-python\n",
    "\n",
    "Lexical and syntactic features: http://www.aicbt.com/authorship-attribution/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cython extension is already loaded. To reload it, use:\n",
      "  %reload_ext cython\n",
      "The cythonmagic extension is already loaded. To reload it, use:\n",
      "  %reload_ext cythonmagic\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, reprlib, sys\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import *\n",
    "import random as ran\n",
    "ran.seed(5125)\n",
    "\n",
    "%load_ext cython\n",
    "%load_ext cythonmagic\n",
    "%matplotlib inline\n",
    "\n",
    "from pandas_confusion import ConfusionMatrix\n",
    "from scipy.cluster.vq import whiten\n",
    "\n",
    "import nltk as n\n",
    "import nltk, nltk.classify.util, nltk.metrics, nltk.tokenize, nltk.stem\n",
    "from nltk.corpus import *\n",
    "from nltk.stem import *\n",
    "from nltk.classify import *\n",
    "from nltk.collocations import *\n",
    "from nltk.metrics import BigramAssocMeasures as BAM\n",
    "from nltk.probability import *\n",
    "from nltk.classify.scikitlearn import *\n",
    "from nltk.tag.sequential import *\n",
    "from nltk.tag import *\n",
    "from nltk.tag.util import *\n",
    "\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn import *\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.svm import *\n",
    "from sklearn.pipeline import *\n",
    "from sklearn.multiclass import *\n",
    "from sklearn.naive_bayes import *\n",
    "from sklearn.neighbors import *\n",
    "from sklearn.feature_selection import *\n",
    "from sklearn.ensemble import *\n",
    "\n",
    "# n.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data and show them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#AUTHID</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>sEXT</th>\n",
       "      <th>sNEU</th>\n",
       "      <th>sAGR</th>\n",
       "      <th>sCON</th>\n",
       "      <th>sOPN</th>\n",
       "      <th>cEXT</th>\n",
       "      <th>cNEU</th>\n",
       "      <th>cAGR</th>\n",
       "      <th>cCON</th>\n",
       "      <th>cOPN</th>\n",
       "      <th>DATE</th>\n",
       "      <th>NETWORKSIZE</th>\n",
       "      <th>BETWEENNESS</th>\n",
       "      <th>NBETWEENNESS</th>\n",
       "      <th>DENSITY</th>\n",
       "      <th>BROKERAGE</th>\n",
       "      <th>NBROKERAGE</th>\n",
       "      <th>TRANSITIVITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
       "      <td>likes the sound of thunder.</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.4</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>06/19/09 03:21 PM</td>\n",
       "      <td>180</td>\n",
       "      <td>14861.6</td>\n",
       "      <td>93.29</td>\n",
       "      <td>0.03</td>\n",
       "      <td>15661</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
       "      <td>is so sleepy it's not even funny that's she ca...</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.4</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>07/02/09 08:41 AM</td>\n",
       "      <td>180</td>\n",
       "      <td>14861.6</td>\n",
       "      <td>93.29</td>\n",
       "      <td>0.03</td>\n",
       "      <td>15661</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            #AUTHID  \\\n",
       "0  b7b7764cfa1c523e4e93ab2a79a946c4   \n",
       "1  b7b7764cfa1c523e4e93ab2a79a946c4   \n",
       "\n",
       "                                              STATUS  sEXT  sNEU  sAGR  sCON  \\\n",
       "0                        likes the sound of thunder.  2.65     3  3.15  3.25   \n",
       "1  is so sleepy it's not even funny that's she ca...  2.65     3  3.15  3.25   \n",
       "\n",
       "   sOPN cEXT cNEU cAGR cCON cOPN               DATE  NETWORKSIZE  BETWEENNESS  \\\n",
       "0   4.4    n    y    n    n    y  06/19/09 03:21 PM          180      14861.6   \n",
       "1   4.4    n    y    n    n    y  07/02/09 08:41 AM          180      14861.6   \n",
       "\n",
       "   NBETWEENNESS  DENSITY  BROKERAGE  NBROKERAGE  TRANSITIVITY  \n",
       "0         93.29     0.03      15661        0.49           0.1  \n",
       "1         93.29     0.03      15661        0.49           0.1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data.csv\", parse_dates=True, infer_datetime_format=True, \n",
    "            sep = None, encoding = \"latin-1\", engine = \"python\")\n",
    "data.head(n=2)\n",
    "# data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = {'n': \"no\", 'y': \"yes\"}\n",
    "\n",
    "# http://stackoverflow.com/a/17702781\n",
    "data = data.replace(d)\n",
    "\n",
    "neu = data[[\"#AUTHID\",\"STATUS\",\"cNEU\"]]\n",
    "ext = data[[\"#AUTHID\",\"STATUS\",\"cEXT\"]]\n",
    "agr = data[[\"#AUTHID\",\"STATUS\",\"cAGR\"]]\n",
    "con = data[[\"#AUTHID\",\"STATUS\",\"cCON\"]]\n",
    "opn = data[[\"#AUTHID\",\"STATUS\",\"cOPN\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into train + test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_neu, test_neu = sk.cross_validation.train_test_split(neu, train_size = 0.66)\n",
    "train_ext, test_ext = sk.cross_validation.train_test_split(ext, train_size = 0.66)\n",
    "train_agr, test_agr = sk.cross_validation.train_test_split(agr, train_size = 0.66)\n",
    "train_con, test_con = sk.cross_validation.train_test_split(con, train_size = 0.66)\n",
    "train_opn, test_opn = sk.cross_validation.train_test_split(opn, train_size = 0.66)\n",
    "# print(len(train_neu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creates diff. pipelines here!\n",
    "\n",
    "with stop_words : ‘english’ in CountVecto or T.Vecto accuracy ussualy lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_names = ['yes', 'no']\n",
    "\n",
    "# Support Vector Machines\n",
    "classifierLinearSVC = Pipeline([\n",
    "    ('vectorizer_tfidf', TfidfVectorizer(ngram_range = (1,3))),\n",
    "    ('clf', LinearSVC())]) # OneVsRestClassifier already implemented, docs: http://scikit-learn.org/stable/modules/svm.html#multi-class-classification\n",
    "\n",
    "classifierSVC = Pipeline([\n",
    "    ('vectorizer_tfidf', TfidfVectorizer(ngram_range = (1,3))),\n",
    "    ('clf', SVC(cache_size=500))]) # \"one-against-one\", docs: http://scikit-learn.org/stable/modules/svm.html#multi-class-classification\n",
    "\n",
    "# Two Naybe Bayes below are also same\n",
    "classifierOVR_NB = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(ngram_range = (1,3))),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', OneVsRestClassifier(MultinomialNB()))]) # OneVsOneClassifier does not play role\n",
    "\n",
    "classifierNB = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(ngram_range = (1,3))),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('nb', MultinomialNB())])\n",
    "\n",
    "classifierBNB = Pipeline([    \n",
    "    ('vectorizer_tfidf', TfidfVectorizer(ngram_range = (1,3))),\n",
    "    ('bnb', BernoulliNB())])\n",
    "\n",
    "# Nearest Neighboars\n",
    "classifier_kNN = Pipeline([\n",
    "    ('vectorizer_tfidf', TfidfVectorizer(ngram_range = (1,3))),\n",
    "    ('kNN', KNeighborsClassifier())]) # http://scikit-learn.org/stable/modules/neighbors.html#neighbors\n",
    "\n",
    "# Random Forest\n",
    "classifierRF = Pipeline([    \n",
    "    ('vectorizer_tfidf', TfidfVectorizer(ngram_range = (1,3))),\n",
    "    ('rfc', RandomForestClassifier(n_jobs=-1))])\n",
    "\n",
    "classifierADC = Pipeline([    \n",
    "    ('vectorizer_tfidf', TfidfVectorizer(ngram_range = (1,3))),\n",
    "    ('adc', AdaBoostClassifier())])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cNEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rbf kernel SVC: 0.625 (+/- 0.00)\n",
      "Accuracy LinearSVC: 0.579 (+/- 0.02)\n",
      "\n",
      "Accuracy of bernuli NB: 0.624 (+/- 0.00)\n",
      "Accuracy NB: 0.625 (+/- 0.00)\n",
      "Accuracy of one-vs-rest NB: 0.625 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "clas_fit_SVC = classifierSVC.fit(train_neu[\"STATUS\"], train_neu[\"cNEU\"])\n",
    "predicted_SVC = classifierSVC.predict(test_neu[\"cNEU\"])\n",
    "scores_SVC = cross_validation.cross_val_score(classifierSVC, neu[\"STATUS\"], neu[\"cNEU\"], cv = 5)\n",
    "print(\"Accuracy rbf kernel SVC: %0.3f (+/- %0.2f)\" % (scores_SVC.mean(), scores_SVC.std() * 2))\n",
    "\n",
    "clas_fit_LSVC = classifierLinearSVC.fit(train_neu[\"STATUS\"], train_neu[\"cNEU\"])\n",
    "predicted_LSVC = classifierLinearSVC.predict(test_neu[\"cNEU\"])\n",
    "scores_LSVC = cross_validation.cross_val_score(classifierLinearSVC, neu[\"STATUS\"], neu[\"cNEU\"], cv = 5)\n",
    "print(\"Accuracy LinearSVC: %0.3f (+/- %0.2f)\" % (scores_LSVC.mean(), scores_LSVC.std() * 2))\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "clas_fit_BNB = classifierBNB.fit(train_neu[\"STATUS\"], train_neu[\"cNEU\"])\n",
    "predicted_BNB = classifierBNB.predict(test_neu[\"cNEU\"])\n",
    "scores_BNB = cross_validation.cross_val_score(classifierBNB, neu[\"STATUS\"], neu[\"cNEU\"], cv = 5)\n",
    "print(\"Accuracy of bernuli NB: %0.3f (+/- %0.2f)\" % (scores_BNB.mean(), scores_BNB.std() * 2))\n",
    "\n",
    "clas_fit_NB = classifierNB.fit(train_neu[\"STATUS\"], train_neu[\"cNEU\"])\n",
    "predicted_NB = classifierNB.predict(test_neu[\"cNEU\"])\n",
    "scores_NB = cross_validation.cross_val_score(classifierNB, neu[\"STATUS\"], neu[\"cNEU\"], cv = 5)\n",
    "print(\"Accuracy NB: %0.3f (+/- %0.2f)\" % (scores_NB.mean(), scores_NB.std() * 2))\n",
    "\n",
    "clas_fit_OVR_NB = classifierOVR_NB.fit(train_neu[\"STATUS\"], train_neu[\"cNEU\"])\n",
    "predicted_OVR_NB = classifierOVR_NB.predict(test_neu[\"cNEU\"])\n",
    "scores_OVR_NB = cross_validation.cross_val_score(classifierOVR_NB, neu[\"STATUS\"], neu[\"cNEU\"], cv = 5)\n",
    "print(\"Accuracy of one-vs-rest NB: %0.3f (+/- %0.2f)\" % (scores_OVR_NB.mean(), scores_OVR_NB.std() * 2))\n",
    "\n",
    "\n",
    "#count = 0\n",
    "#for item, labels in zip(test_neu[\"STATUS\"], predicted_SVC):\n",
    "#    count += 1\n",
    "# print(count) # just for checking the count above +- 6000 and here 3372"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of kNN: 0.409 (+/- 0.05)\n",
      "\n",
      "Accuracy of AdaBoost: 0.606 (+/- 0.02)\n",
      "Accuracy of random Forest: 0.593 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "clas_fit_kNN = classifier_kNN.fit(train_neu[\"STATUS\"], train_neu[\"cNEU\"])\n",
    "predicted_kNN = classifier_kNN.predict(test_neu[\"cNEU\"])\n",
    "scores_kNN = cross_validation.cross_val_score(classifier_kNN, neu[\"STATUS\"], neu[\"cNEU\"], cv = 5)\n",
    "print(\"Accuracy of kNN: %0.3f (+/- %0.2f)\" % (scores_kNN.mean(), scores_kNN.std() * 2))\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "clas_fit_ADC = classifierADC.fit(train_neu[\"STATUS\"], train_neu[\"cNEU\"])\n",
    "predicted_ADC = classifierADC.predict(test_neu[\"cNEU\"])\n",
    "scores_ADC = cross_validation.cross_val_score(classifierADC, neu[\"STATUS\"], neu[\"cNEU\"], cv = 5)\n",
    "print(\"Accuracy of AdaBoost: %0.3f (+/- %0.2f)\" % (scores_ADC.mean(), scores_ADC.std() * 2))\n",
    "\n",
    "clas_fit_RF = classifierRF.fit(train_neu[\"STATUS\"], train_neu[\"cNEU\"])\n",
    "predicted_RF = classifierRF.predict(test_neu[\"cNEU\"])\n",
    "scores_RF = cross_validation.cross_val_score(classifierRF, neu[\"STATUS\"], neu[\"cNEU\"], cv = 5)\n",
    "print(\"Accuracy of random Forest: %0.3f (+/- %0.2f)\" % (scores_RF.mean(), scores_RF.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VotingClassifier cNUE\n",
    "\n",
    "http://scikit-learn.org/stable/modules/ensemble.html#votingclassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.625 (+/- 0.00) [SVC]\n",
      "Accuracy: 0.579 (+/- 0.01) [LSVC]\n",
      "Accuracy: 0.624 (+/- 0.00) [BNB]\n",
      "Accuracy: 0.625 (+/- 0.00) [NB]\n",
      "Accuracy: 0.625 (+/- 0.00) [OVR_NB]\n",
      "Accuracy: 0.409 (+/- 0.03) [kNN]\n",
      "Accuracy: 0.596 (+/- 0.02) [Random Forest]\n",
      "Accuracy: 0.606 (+/- 0.01) [ADC]\n",
      "Accuracy: 0.625 (+/- 0.00) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "eclf = VotingClassifier(estimators=[\n",
    "        (\"svc\", clas_fit_SVC),\n",
    "        (\"linear_svc\", clas_fit_LSVC), \n",
    "        (\"bnb\", clas_fit_BNB),\n",
    "        (\"nb\", clas_fit_NB),\n",
    "        (\"ovr_nb\", clas_fit_OVR_NB),\n",
    "        (\"kNN\", clas_fit_kNN), \n",
    "        (\"rf\", clas_fit_RF), \n",
    "        (\"adc\", clas_fit_ADC)], voting='hard')\n",
    "\n",
    "\n",
    "for clf, label in zip([clas_fit_SVC, clas_fit_LSVC, clas_fit_BNB, clas_fit_NB, clas_fit_OVR_NB, clas_fit_kNN, clas_fit_RF, clas_fit_ADC, eclf], [\"SVC\", \"LSVC\",\"BNB\",\"NB\",\"OVR_NB\", 'kNN', 'Random Forest', 'ADC', 'Ensemble']):\n",
    "    scores = cross_validation.cross_val_score(clf, neu[\"STATUS\"], neu[\"cNEU\"], cv=5, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.3f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### cAGR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy rbf kernel SVC: 0.531 (+/- 0.00)\n",
      "Accuracy LinearSVC: 0.512 (+/- 0.03)\n",
      "\n",
      "Accuracy of bernuli NB: 0.531 (+/- 0.02)\n",
      "Accuracy NB: 0.526 (+/- 0.02)\n",
      "Accuracy of one-vs-rest NB: 0.526 (+/- 0.02)\n",
      "\n",
      "Accuracy of kNN: 0.483 (+/- 0.01)\n",
      "\n",
      "Accuracy of AdaBoost: 0.513 (+/- 0.05)\n",
      "Accuracy of random Forest: 0.502 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "clas_fit_SVC = classifierSVC.fit(train_agr[\"STATUS\"], train_agr[\"cAGR\"])\n",
    "predicted_SVC = classifierSVC.predict(test_agr[\"cAGR\"])\n",
    "scores_SVC = cross_validation.cross_val_score(classifierSVC, agr[\"STATUS\"], agr[\"cAGR\"], cv = 5)\n",
    "print(\"Accuracy rbf kernel SVC: %0.3f (+/- %0.2f)\" % (scores_SVC.mean(), scores_SVC.std() * 2))\n",
    "\n",
    "clas_fit_LSVC = classifierLinearSVC.fit(train_agr[\"STATUS\"], train_agr[\"cAGR\"])\n",
    "predicted_LSVC = classifierLinearSVC.predict(test_agr[\"cAGR\"])\n",
    "scores_LSVC = cross_validation.cross_val_score(classifierLinearSVC, agr[\"STATUS\"], agr[\"cAGR\"], cv = 5)\n",
    "print(\"Accuracy LinearSVC: %0.3f (+/- %0.2f)\" % (scores_LSVC.mean(), scores_LSVC.std() * 2))\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "clas_fit_BNB = classifierBNB.fit(train_agr[\"STATUS\"], train_agr[\"cAGR\"])\n",
    "predicted_BNB = classifierBNB.predict(test_agr[\"cAGR\"])\n",
    "scores_BNB = cross_validation.cross_val_score(classifierBNB, agr[\"STATUS\"], agr[\"cAGR\"], cv = 5)\n",
    "print(\"Accuracy of bernuli NB: %0.3f (+/- %0.2f)\" % (scores_BNB.mean(), scores_BNB.std() * 2))\n",
    "\n",
    "clas_fit_NB = classifierNB.fit(train_agr[\"STATUS\"], train_agr[\"cAGR\"])\n",
    "predicted_NB = classifierNB.predict(test_agr[\"cAGR\"])\n",
    "scores_NB = cross_validation.cross_val_score(classifierNB, agr[\"STATUS\"], agr[\"cAGR\"], cv = 5)\n",
    "print(\"Accuracy NB: %0.3f (+/- %0.2f)\" % (scores_NB.mean(), scores_NB.std() * 2))\n",
    "\n",
    "clas_fit_OVR_NB = classifierOVR_NB.fit(train_agr[\"STATUS\"], train_agr[\"cAGR\"])\n",
    "predicted_OVR_NB = classifierOVR_NB.predict(test_agr[\"cAGR\"])\n",
    "scores_OVR_NB = cross_validation.cross_val_score(classifierOVR_NB, agr[\"STATUS\"], agr[\"cAGR\"], cv = 5)\n",
    "print(\"Accuracy of one-vs-rest NB: %0.3f (+/- %0.2f)\" % (scores_OVR_NB.mean(), scores_OVR_NB.std() * 2))\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "clas_fit_kNN = classifier_kNN.fit(train_agr[\"STATUS\"], train_agr[\"cAGR\"])\n",
    "predicted_kNN = classifier_kNN.predict(test_agr[\"cAGR\"])\n",
    "scores_kNN = cross_validation.cross_val_score(classifier_kNN, agr[\"STATUS\"], agr[\"cAGR\"], cv = 5)\n",
    "print(\"Accuracy of kNN: %0.3f (+/- %0.2f)\" % (scores_kNN.mean(), scores_kNN.std() * 2))\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "clas_fit_ADC = classifierADC.fit(train_agr[\"STATUS\"], train_agr[\"cAGR\"])\n",
    "predicted_ADC = classifierADC.predict(test_agr[\"cAGR\"])\n",
    "scores_ADC = cross_validation.cross_val_score(classifierADC, agr[\"STATUS\"], agr[\"cAGR\"], cv = 5)\n",
    "print(\"Accuracy of AdaBoost: %0.3f (+/- %0.2f)\" % (scores_ADC.mean(), scores_ADC.std() * 2))\n",
    "\n",
    "clas_fit_RF = classifierRF.fit(train_agr[\"STATUS\"], train_agr[\"cAGR\"])\n",
    "predicted_RF = classifierRF.predict(test_agr[\"cAGR\"])\n",
    "scores_RF = cross_validation.cross_val_score(classifierRF, agr[\"STATUS\"], agr[\"cAGR\"], cv = 5)\n",
    "print(\"Accuracy of random Forest: %0.3f (+/- %0.2f)\" % (scores_RF.mean(), scores_RF.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VotingClassifier cAGR\n",
    "\n",
    "http://scikit-learn.org/stable/modules/ensemble.html#votingclassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.531 (+/- 0.00) [SVC]\n",
      "Accuracy: 0.512 (+/- 0.02) [LSVC]\n",
      "Accuracy: 0.531 (+/- 0.01) [BNB]\n",
      "Accuracy: 0.526 (+/- 0.01) [NB]\n",
      "Accuracy: 0.526 (+/- 0.01) [OVR_NB]\n",
      "Accuracy: 0.483 (+/- 0.01) [kNN]\n",
      "Accuracy: 0.500 (+/- 0.01) [Random Forest]\n",
      "Accuracy: 0.513 (+/- 0.02) [ADC]"
     ]
    }
   ],
   "source": [
    "eclf = VotingClassifier(estimators=[\n",
    "        (\"svc\", clas_fit_SVC),\n",
    "        (\"linear_svc\", clas_fit_LSVC), \n",
    "        (\"bnb\", clas_fit_BNB),\n",
    "        (\"nb\", clas_fit_NB),\n",
    "        (\"ovr_nb\", clas_fit_OVR_NB),\n",
    "        (\"kNN\", clas_fit_kNN), \n",
    "        (\"rf\", clas_fit_RF), \n",
    "        (\"adc\", clas_fit_ADC)], voting='hard')\n",
    "\n",
    "\n",
    "for clf, label in zip([clas_fit_SVC, clas_fit_LSVC, clas_fit_BNB, clas_fit_NB, clas_fit_OVR_NB, clas_fit_kNN, clas_fit_RF, clas_fit_ADC, eclf], [\"SVC\", \"LSVC\",\"BNB\",\"NB\",\"OVR_NB\", 'kNN', 'Random Forest', 'ADC', 'Ensemble']):\n",
    "    scores = cross_validation.cross_val_score(clf, agr[\"STATUS\"], agr[\"cAGR\"], cv=5, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.3f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cOPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clas_fit_SVC = classifierSVC.fit(train_opn[\"STATUS\"], train_opn[\"cOPN\"])\n",
    "predicted_SVC = classifierSVC.predict(test_opn[\"cOPN\"])\n",
    "scores_SVC = cross_validation.cross_val_score(classifierSVC, opn[\"STATUS\"], opn[\"cOPN\"], cv = 5)\n",
    "print(\"Accuracy rbf kernel SVC: %0.3f (+/- %0.2f)\" % (scores_SVC.mean(), scores_SVC.std() * 2))\n",
    "\n",
    "clas_fit_LSVC = classifierLinearSVC.fit(train_opn[\"STATUS\"], train_opn[\"cOPN\"])\n",
    "predicted_LSVC = classifierLinearSVC.predict(test_opn[\"cOPN\"])\n",
    "scores_LSVC = cross_validation.cross_val_score(classifierLinearSVC, opn[\"STATUS\"], opn[\"cOPN\"], cv = 5)\n",
    "print(\"Accuracy LinearSVC: %0.3f (+/- %0.2f)\" % (scores_LSVC.mean(), scores_LSVC.std() * 2))\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "clas_fit_BNB = classifierBNB.fit(train_opn[\"STATUS\"], train_opn[\"cOPN\"])\n",
    "predicted_BNB = classifierBNB.predict(test_opn[\"cOPN\"])\n",
    "scores_BNB = cross_validation.cross_val_score(classifierBNB, opn[\"STATUS\"], opn[\"cOPN\"], cv = 5)\n",
    "print(\"Accuracy of bernuli NB: %0.3f (+/- %0.2f)\" % (scores_BNB.mean(), scores_BNB.std() * 2))\n",
    "\n",
    "clas_fit_NB = classifierNB.fit(train_opn[\"STATUS\"], train_opn[\"cOPN\"])\n",
    "predicted_NB = classifierNB.predict(test_opn[\"cOPN\"])\n",
    "scores_NB = cross_validation.cross_val_score(classifierNB, opn[\"STATUS\"], opn[\"cOPN\"], cv = 5)\n",
    "print(\"Accuracy NB: %0.3f (+/- %0.2f)\" % (scores_NB.mean(), scores_NB.std() * 2))\n",
    "\n",
    "clas_fit_OVR_NB = classifierOVR_NB.fit(train_opn[\"STATUS\"], train_opn[\"cOPN\"])\n",
    "predicted_OVR_NB = classifierOVR_NB.predict(test_opn[\"cOPN\"])\n",
    "scores_OVR_NB = cross_validation.cross_val_score(classifierOVR_NB, opn[\"STATUS\"], opn[\"cOPN\"], cv = 5)\n",
    "print(\"Accuracy of one-vs-rest NB: %0.3f (+/- %0.2f)\" % (scores_OVR_NB.mean(), scores_OVR_NB.std() * 2))\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "clas_fit_kNN = classifier_kNN.fit(train_opn[\"STATUS\"], train_opn[\"cOPN\"])\n",
    "predicted_kNN = classifier_kNN.predict(test_opn[\"cOPN\"])\n",
    "scores_kNN = cross_validation.cross_val_score(classifier_kNN, opn[\"STATUS\"], opn[\"cOPN\"], cv = 5)\n",
    "print(\"Accuracy of kNN: %0.3f (+/- %0.2f)\" % (scores_kNN.mean(), scores_kNN.std() * 2))\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "clas_fit_ADC = classifierADC.fit(train_opn[\"STATUS\"], train_opn[\"cOPN\"])\n",
    "predicted_ADC = classifierADC.predict(test_opn[\"cOPN\"])\n",
    "scores_ADC = cross_validation.cross_val_score(classifierADC, opn[\"STATUS\"], opn[\"cOPN\"], cv = 5)\n",
    "print(\"Accuracy of AdaBoost: %0.3f (+/- %0.2f)\" % (scores_ADC.mean(), scores_ADC.std() * 2))\n",
    "\n",
    "clas_fit_RF = classifierRF.fit(train_opn[\"STATUS\"], train_opn[\"cOPN\"])\n",
    "predicted_RF = classifierRF.predict(test_opn[\"cOPN\"])\n",
    "scores_RF = cross_validation.cross_val_score(classifierRF, opn[\"STATUS\"], opn[\"cOPN\"], cv = 5)\n",
    "print(\"Accuracy of random Forest: %0.3f (+/- %0.2f)\" % (scores_RF.mean(), scores_RF.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VotingClassifier cOPN\n",
    "\n",
    "http://scikit-learn.org/stable/modules/ensemble.html#votingclassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eclf = VotingClassifier(estimators=[\n",
    "        (\"svc\", clas_fit_SVC),\n",
    "        (\"linear_svc\", clas_fit_LSVC), \n",
    "        (\"bnb\", clas_fit_BNB),\n",
    "        (\"nb\", clas_fit_NB),\n",
    "        (\"ovr_nb\", clas_fit_OVR_NB),\n",
    "        (\"kNN\", clas_fit_kNN), \n",
    "        (\"rf\", clas_fit_RF), \n",
    "        (\"adc\", clas_fit_ADC)], voting='hard')\n",
    "\n",
    "\n",
    "for clf, label in zip([clas_fit_SVC, clas_fit_LSVC, clas_fit_BNB, clas_fit_NB, clas_fit_OVR_NB, clas_fit_kNN, clas_fit_RF, clas_fit_ADC, eclf], [\"SVC\", \"LSVC\",\"BNB\",\"NB\",\"OVR_NB\", 'kNN', 'Random Forest', 'ADC', 'Ensemble']):\n",
    "    scores = cross_validation.cross_val_score(clf, opn[\"STATUS\"], opn[\"cOPN\"], cv=5, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.3f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cCON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clas_fit_SVC = classifierSVC.fit(train_con[\"STATUS\"], train_con[\"cCON\"])\n",
    "predicted_SVC = classifierSVC.predict(test_con[\"cCON\"])\n",
    "scores_SVC = cross_validation.cross_val_score(classifierSVC, con[\"STATUS\"], con[\"cCON\"], cv = 5)\n",
    "print(\"Accuracy rbf kernel SVC: %0.3f (+/- %0.2f)\" % (scores_SVC.mean(), scores_SVC.std() * 2))\n",
    "\n",
    "clas_fit_LSVC = classifierLinearSVC.fit(train_con[\"STATUS\"], train_con[\"cCON\"])\n",
    "predicted_LSVC = classifierLinearSVC.predict(test_con[\"cCON\"])\n",
    "scores_LSVC = cross_validation.cross_val_score(classifierLinearSVC, con[\"STATUS\"], con[\"cCON\"], cv = 5)\n",
    "print(\"Accuracy LinearSVC: %0.3f (+/- %0.2f)\" % (scores_LSVC.mean(), scores_LSVC.std() * 2))\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "clas_fit_BNB = classifierBNB.fit(train_con[\"STATUS\"], train_con[\"cCON\"])\n",
    "predicted_BNB = classifierBNB.predict(test_con[\"cCON\"])\n",
    "scores_BNB = cross_validation.cross_val_score(classifierBNB, con[\"STATUS\"], con[\"cCON\"], cv = 5)\n",
    "print(\"Accuracy of bernuli NB: %0.3f (+/- %0.2f)\" % (scores_BNB.mean(), scores_BNB.std() * 2))\n",
    "\n",
    "clas_fit_NB = classifierNB.fit(train_con[\"STATUS\"], train_con[\"cCON\"])\n",
    "predicted_NB = classifierNB.predict(test_con[\"cCON\"])\n",
    "scores_NB = cross_validation.cross_val_score(classifierNB, con[\"STATUS\"], con[\"cCON\"], cv = 5)\n",
    "print(\"Accuracy NB: %0.3f (+/- %0.2f)\" % (scores_NB.mean(), scores_NB.std() * 2))\n",
    "\n",
    "clas_fit_OVR_NB = classifierOVR_NB.fit(train_con[\"STATUS\"], train_con[\"cCON\"])\n",
    "predicted_OVR_NB = classifierOVR_NB.predict(test_con[\"cCON\"])\n",
    "scores_OVR_NB = cross_validation.cross_val_score(classifierOVR_NB, con[\"STATUS\"], con[\"cCON\"], cv = 5)\n",
    "print(\"Accuracy of one-vs-rest NB: %0.3f (+/- %0.2f)\" % (scores_OVR_NB.mean(), scores_OVR_NB.std() * 2))\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "clas_fit_kNN = classifier_kNN.fit(train_con[\"STATUS\"], train_con[\"cCON\"])\n",
    "predicted_kNN = classifier_kNN.predict(test_con[\"cCON\"])\n",
    "scores_kNN = cross_validation.cross_val_score(classifier_kNN, con[\"STATUS\"], con[\"cCON\"], cv = 5)\n",
    "print(\"Accuracy of kNN: %0.3f (+/- %0.2f)\" % (scores_kNN.mean(), scores_kNN.std() * 2))\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "clas_fit_ADC = classifierADC.fit(train_con[\"STATUS\"], train_con[\"cCON\"])\n",
    "predicted_ADC = classifierADC.predict(test_con[\"cCON\"])\n",
    "scores_ADC = cross_validation.cross_val_score(classifierADC, con[\"STATUS\"], con[\"cCON\"], cv = 5)\n",
    "print(\"Accuracy of AdaBoost: %0.3f (+/- %0.2f)\" % (scores_ADC.mean(), scores_ADC.std() * 2))\n",
    "\n",
    "clas_fit_RF = classifierRF.fit(train_con[\"STATUS\"], train_con[\"cCON\"])\n",
    "predicted_RF = classifierRF.predict(test_con[\"cCON\"])\n",
    "scores_RF = cross_validation.cross_val_score(classifierRF, con[\"STATUS\"], con[\"cCON\"], cv = 5)\n",
    "print(\"Accuracy of random Forest: %0.3f (+/- %0.2f)\" % (scores_RF.mean(), scores_RF.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VotingClassifier cCON\n",
    "\n",
    "http://scikit-learn.org/stable/modules/ensemble.html#votingclassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eclf = VotingClassifier(estimators=[\n",
    "        (\"svc\", clas_fit_SVC),\n",
    "        (\"linear_svc\", clas_fit_LSVC), \n",
    "        (\"bnb\", clas_fit_BNB),\n",
    "        (\"nb\", clas_fit_NB),\n",
    "        (\"ovr_nb\", clas_fit_OVR_NB),\n",
    "        (\"kNN\", clas_fit_kNN), \n",
    "        (\"rf\", clas_fit_RF), \n",
    "        (\"adc\", clas_fit_ADC)], voting='hard')\n",
    "\n",
    "\n",
    "for clf, label in zip([clas_fit_SVC, clas_fit_LSVC, clas_fit_BNB, clas_fit_NB, clas_fit_OVR_NB, clas_fit_kNN, clas_fit_RF, clas_fit_ADC, eclf], [\"SVC\", \"LSVC\",\"BNB\",\"NB\",\"OVR_NB\", 'kNN', 'Random Forest', 'ADC', 'Ensemble']):\n",
    "    scores = cross_validation.cross_val_score(clf, con[\"STATUS\"], con[\"cCON\"], cv=5, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.3f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clas_fit_SVC = classifierSVC.fit(train_ext[\"STATUS\"], train_ext[\"cEXT\"])\n",
    "predicted_SVC = classifierSVC.predict(test_ext[\"cEXT\"])\n",
    "scores_SVC = cross_validation.cross_val_score(classifierSVC, ext[\"STATUS\"], ext[\"cEXT\"], cv = 5)\n",
    "print(\"Accuracy rbf kernel SVC: %0.3f (+/- %0.2f)\" % (scores_SVC.mean(), scores_SVC.std() * 2))\n",
    "\n",
    "clas_fit_LSVC = classifierLinearSVC.fit(train_ext[\"STATUS\"], train_ext[\"cEXT\"])\n",
    "predicted_LSVC = classifierLinearSVC.predict(test_ext[\"cEXT\"])\n",
    "scores_LSVC = cross_validation.cross_val_score(classifierLinearSVC, ext[\"STATUS\"], ext[\"cEXT\"], cv = 5)\n",
    "print(\"Accuracy LinearSVC: %0.3f (+/- %0.2f)\" % (scores_LSVC.mean(), scores_LSVC.std() * 2))\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "clas_fit_BNB = classifierBNB.fit(train_ext[\"STATUS\"], train_ext[\"cEXT\"])\n",
    "predicted_BNB = classifierBNB.predict(test_ext[\"cEXT\"])\n",
    "scores_BNB = cross_validation.cross_val_score(classifierBNB, ext[\"STATUS\"], ext[\"cEXT\"], cv = 5)\n",
    "print(\"Accuracy of bernuli NB: %0.3f (+/- %0.2f)\" % (scores_BNB.mean(), scores_BNB.std() * 2))\n",
    "\n",
    "clas_fit_NB = classifierNB.fit(train_ext[\"STATUS\"], train_ext[\"cEXT\"])\n",
    "predicted_NB = classifierNB.predict(test_ext[\"cEXT\"])\n",
    "scores_NB = cross_validation.cross_val_score(classifierNB, ext[\"STATUS\"], ext[\"cEXT\"], cv = 5)\n",
    "print(\"Accuracy NB: %0.3f (+/- %0.2f)\" % (scores_NB.mean(), scores_NB.std() * 2))\n",
    "\n",
    "clas_fit_OVR_NB = classifierOVR_NB.fit(train_ext[\"STATUS\"], train_ext[\"cEXT\"])\n",
    "predicted_OVR_NB = classifierOVR_NB.predict(test_ext[\"cEXT\"])\n",
    "scores_OVR_NB = cross_validation.cross_val_score(classifierOVR_NB, ext[\"STATUS\"], ext[\"cEXT\"], cv = 5)\n",
    "print(\"Accuracy of one-vs-rest NB: %0.3f (+/- %0.2f)\" % (scores_OVR_NB.mean(), scores_OVR_NB.std() * 2))\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "clas_fit_kNN = classifier_kNN.fit(train_ext[\"STATUS\"], train_ext[\"cEXT\"])\n",
    "predicted_kNN = classifier_kNN.predict(test_ext[\"cEXT\"])\n",
    "scores_kNN = cross_validation.cross_val_score(classifier_kNN, ext[\"STATUS\"], ext[\"cEXT\"], cv = 5)\n",
    "print(\"Accuracy of kNN: %0.3f (+/- %0.2f)\" % (scores_kNN.mean(), scores_kNN.std() * 2))\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "clas_fit_ADC = classifierADC.fit(train_ext[\"STATUS\"], train_ext[\"cEXT\"])\n",
    "predicted_ADC = classifierADC.predict(test_ext[\"cEXT\"])\n",
    "scores_ADC = cross_validation.cross_val_score(classifierADC, ext[\"STATUS\"], ext[\"cEXT\"], cv = 5)\n",
    "print(\"Accuracy of AdaBoost: %0.3f (+/- %0.2f)\" % (scores_ADC.mean(), scores_ADC.std() * 2))\n",
    "\n",
    "clas_fit_RF = classifierRF.fit(train_ext[\"STATUS\"], train_ext[\"cEXT\"])\n",
    "predicted_RF = classifierRF.predict(test_ext[\"cEXT\"])\n",
    "scores_RF = cross_validation.cross_val_score(classifierRF, ext[\"STATUS\"], ext[\"cEXT\"], cv = 5)\n",
    "print(\"Accuracy of random Forest: %0.3f (+/- %0.2f)\" % (scores_RF.mean(), scores_RF.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VotingClassifier cEXT\n",
    "\n",
    "http://scikit-learn.org/stable/modules/ensemble.html#votingclassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eclf = VotingClassifier(estimators=[\n",
    "        (\"svc\", clas_fit_SVC),\n",
    "        (\"linear_svc\", clas_fit_LSVC), \n",
    "        (\"bnb\", clas_fit_BNB),\n",
    "        (\"nb\", clas_fit_NB),\n",
    "        (\"ovr_nb\", clas_fit_OVR_NB),\n",
    "        (\"kNN\", clas_fit_kNN), \n",
    "        (\"rf\", clas_fit_RF), \n",
    "        (\"adc\", clas_fit_ADC)], voting='hard')\n",
    "\n",
    "\n",
    "for clf, label in zip([clas_fit_SVC, clas_fit_LSVC, clas_fit_BNB, clas_fit_NB, clas_fit_OVR_NB, clas_fit_kNN, clas_fit_RF, clas_fit_ADC, eclf], [\"SVC\", \"LSVC\",\"BNB\",\"NB\",\"OVR_NB\", 'kNN', 'Random Forest', 'ADC', 'Ensemble']):\n",
    "    scores = cross_validation.cross_val_score(clf, ext[\"STATUS\"], ext[\"cEXT\"], cv=5, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.3f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Lexical and other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def LexicalFeatures(chapters):\n",
    "    \"\"\"\n",
    "    Compute feature vectors for word and punctuation features\n",
    "    \"\"\"\n",
    "    sentence_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    word_tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "    num_chapters = len(chapters)\n",
    "    fvs_lexical = np.zeros((len(chapters), 3), np.float64)\n",
    "    fvs_punct = np.zeros((len(chapters), 3), np.float64)\n",
    "    for e, ch_text in enumerate(chapters):\n",
    "        # note: the nltk.word_tokenize includes punctuation\n",
    "        tokens = n.word_tokenize(ch_text.lower())\n",
    "        words = word_tokenizer.tokenize(ch_text.lower())\n",
    "        sentences = sentence_tokenizer.tokenize(ch_text)\n",
    "        vocab = set(words)\n",
    "        words_per_sentence = np.array([len(word_tokenizer.tokenize(s))\n",
    "                                       for s in sentences])\n",
    "\n",
    "        # average number of words per sentence\n",
    "        fvs_lexical[e, 0] = words_per_sentence.mean()\n",
    "        # sentence length variation\n",
    "        fvs_lexical[e, 1] = words_per_sentence.std()\n",
    "        # Lexical diversity\n",
    "        fvs_lexical[e, 2] = len(vocab) / float(len(words))\n",
    "\n",
    "        # Commas per sentence\n",
    "        fvs_punct[e, 0] = tokens.count(',') / float(len(sentences))\n",
    "        # Semicolons per sentence\n",
    "        fvs_punct[e, 1] = tokens.count(';') / float(len(sentences))\n",
    "        # Colons per sentence\n",
    "        fvs_punct[e, 2] = tokens.count(':') / float(len(sentences))\n",
    "\n",
    "    # apply whitening to decorrelate the features\n",
    "    fvs_lexical = whiten(fvs_lexical)\n",
    "    fvs_punct = whiten(fvs_punct)\n",
    "\n",
    "    return fvs_lexical, fvs_punct\n",
    "\n",
    "def SyntacticFeatures(chapters):\n",
    "    \"\"\"\n",
    "    Extract feature vector for part of speech frequencies\n",
    "    \"\"\"\n",
    "    def token_to_pos(ch):\n",
    "        tokens = n.word_tokenize(ch)\n",
    "        return [p[1] for p in n.pos_tag(tokens)]\n",
    "\n",
    "    chapters_pos = [token_to_pos(ch) for ch in chapters]\n",
    "    pos_list = ['NN', 'NNP', 'DT', 'IN', 'JJ', 'NNS']\n",
    "    fvs_syntax = np.array([[ch.count(pos) for pos in pos_list]\n",
    "                           for ch in chapters_pos]).astype(np.float64)\n",
    "\n",
    "    # normalise by dividing each row by number of tokens in the chapter\n",
    "    fvs_syntax /= np.c_[np.array([len(ch) for ch in chapters_pos])]\n",
    "\n",
    "    return fvs_syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/scipy/cluster/vq.py:148: RuntimeWarning: Some columns have standard deviation zero. The values of these columns will not change.\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 99.58915654,   0.        ,  99.58915654],\n",
       "        [  0.        ,   0.        ,   0.        ],\n",
       "        [  0.        ,   0.        ,   0.        ],\n",
       "        ..., \n",
       "        [  0.        ,   0.        ,   0.        ],\n",
       "        [  0.        ,   0.        ,   0.        ],\n",
       "        [  0.        ,   0.        ,   0.        ]]), array([[ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.]]), array([[ 1.,  0.,  0.,  0.,  0.,  0.]])]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_sets = list(LexicalFeatures(neu[[\"STATUS\"]]))\n",
    "feature_sets.append(SyntacticFeatures(neu[[\"STATUS\"]]))\n",
    "feature_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
