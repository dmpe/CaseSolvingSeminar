{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy\n",
    "import pandas\n",
    "import sklearn\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "import csshelper\n",
    "import cssfeature\n",
    "import csspipe\n",
    "import csstransformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Load data\n",
    "(run bash ./src/init.sh first!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            sentence  cNeu\n",
      "0                        likes the sound of thunder.  True\n",
      "1  is so sleepy it's not even funny that's she ca...  True\n",
      "2  is sore and wants the knot of muscles at the b...  True\n",
      "                                            sentence  sNeu\n",
      "0                        likes the sound of thunder.     3\n",
      "1  is so sleepy it's not even funny that's she ca...     3\n",
      "2  is sore and wants the knot of muscles at the b...     3\n"
     ]
    }
   ],
   "source": [
    "#data = pd.read_csv(\"../raw_data/data_n.csv\", parse_dates=True, infer_datetime_format=True)\n",
    "#help(data.head)\n",
    "#data.head(1)\n",
    "db_path = './data.sqlite3'\n",
    "sqlite_connection = sqlite3.connect(db_path)\n",
    "\n",
    "cNeu_reader = csshelper.CNeuReader(sqlite_connection)\n",
    "sNeu_reader = csshelper.SNeuReader(sqlite_connection)\n",
    "\n",
    "print(cNeu_reader.get_results().head(3))\n",
    "print(sNeu_reader.get_results().head(3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "# Create DataFrame with string-length-featues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-b96ffb9fbc00>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m## create length of sentence feature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#sl_data = cssfeature.CharacterFeatures.string_length(cNeu_reader.get_results(), column=0, column_name='sentence_length')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "print(data.head(2))\n",
    "\n",
    "## create length of sentence feature\n",
    "#sl_data = cssfeature.CharacterFeatures.string_length(cNeu_reader.get_results(), column=0, column_name='sentence_length')\n",
    "\n",
    "#print(sl_data.head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sl_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-d8aa7366c0c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msl_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sentence_length'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msl_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cNeu'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sl_data' is not defined"
     ]
    }
   ],
   "source": [
    "features = sl_data[['sentence_length']].astype(str)\n",
    "labels = sl_data[['cNeu']].astype(bool)\n",
    "\n",
    "print(features.head(2))\n",
    "print(labels.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-349d2745daea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msplit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_validation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.66\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m6432119\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtrain_feat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_feat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'features' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "split = sklearn.cross_validation.train_test_split(features, labels, train_size = 0.66, random_state= 6432119)\n",
    "\n",
    "train_feat, test_feat, train_label, test_label = split\n",
    "\n",
    "\"\"\"\n",
    "print(\"train_feat\\n%s\\n\" %train_feat.head(1))\n",
    "print(\"train_label\\n%s\\n\" %train_label.head(1))\n",
    "print(\"test_feat\\n%s\\n\" %test_feat.head(1))\n",
    "print(\"test_label\\n%s\\n\" %test_label.head(1))\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create pipefactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipefactory = csspipe.PipeFactory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Create classifiers for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "multinomial_nb = pipefactory.classifiers.multinomial_nb\n",
    "bernoulli_nb = pipefactory.classifiers.bernoulli_nb\n",
    "\n",
    "svc = pipefactory.classifiers.svc\n",
    "linear_svc = pipefactory.classifiers.linear_svc\n",
    "\n",
    "random_forest = pipefactory.classifiers.random_forest_classifier\n",
    "k_neighbors = pipefactory.classifiers.k_neighors_classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Create extractors for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "tfidf_vectorizer = pipefactory.extractors.tfidf_vectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Create selectors for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k_best = pipefactory.selectors.select_k_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import tag\n",
    "from nltk.corpus import treebank\n",
    "\n",
    "postagger = nltk.tag.ClassifierBasedPOSTagger(train=treebank.tagged_sents())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mytagger = csstransformer.PartOfSpeech(ignore_unknown=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-96f76dce5c39>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#postagger.evaluate(treebank.tagged_sents())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#print(postagger.tag_sents(input))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "#postagger.evaluate(treebank.tagged_sents())\n",
    "input = data.sentence[:5,]\n",
    "print()\n",
    "#print(postagger.tag_sents(input))\n",
    "print()\n",
    "#print(mytagger.transform(input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Findings:\n",
    "-  ngrams ranging from 2-3 return better results than 1-1\n",
    "- full Part-Of-Speech of a sentence + tfidf does not behave well\n",
    "\n",
    "###Why pos tagging failed:\n",
    "We used tfidf to build vectors. tfidf's purpose however, is to *minimize the impact of frequently repeting components* (words). Thus the \"part of speech\"-equivalent of a sentence consisting of a description such as 'NN' will have less impact than a sentence build out of real words, as they are way less frequent in the whole test data.\n",
    "\n",
    "\n",
    "###POS-Workarounds\n",
    "- instead of converting a full sentence into POS-Tag one could try to filter all nouns or adjectives\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_reader_collection = [\n",
    "        ('cExt', csshelper.CExtReader(sqlite_connection))\n",
    "        , ('sExt', csshelper.SExtReader(sqlite_connection))\n",
    "    \n",
    "        , ('cNeu', csshelper.CNeuReader(sqlite_connection))\n",
    "        , ('sNeu', csshelper.SNeuReader(sqlite_connection))\n",
    "     \n",
    "        , ('cAgr', csshelper.CAgrReader(sqlite_connection))\n",
    "        , ('sAgr', csshelper.SAgrReader(sqlite_connection))\n",
    "    \n",
    "        , ('cCon', csshelper.CConReader(sqlite_connection))\n",
    "        , ('sCon', csshelper.SConReader(sqlite_connection))\n",
    "    \n",
    "        , ('cOpn', csshelper.COpnReader(sqlite_connection))\n",
    "        , ('sOpn', csshelper.SOpnReader(sqlite_connection))\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline_collection = [\n",
    "    # 3 Support Vector Machines\n",
    "    ('classifierLinearSVC', pipefactory.create_pipe([\n",
    "        ('tfidf', sklearn.feature_extraction.text.TfidfVectorizer()),\n",
    "        ('clf', sklearn.svm.LinearSVC(random_state = 5152))]) # OneVsRestClassifier already implemented, docs: http://scikit-learn.org/stable/modules/svm.html#multi-class-classification\n",
    "    )\n",
    "    \n",
    "    , ('classifierSVC', pipefactory.create_pipe([\n",
    "        ('vectorizer_tfidf', sklearn.feature_extraction.text.TfidfVectorizer(ngram_range = (1,2))),\n",
    "        ('clf', sklearn.svm.SVC(cache_size=500, random_state = 5152, kernel = \"rbf\", decision_function_shape = \"ovr\"))]) # \"one-against-one\", docs: http://scikit-learn.org/stable/modules/svm.html#multi-class-classification\n",
    "    )\n",
    "    # 2 Naive Bayes\n",
    "    , ('classifierNB', pipefactory.create_pipe([\n",
    "        ('vectorizer_tfidf', sklearn.feature_extraction.text.TfidfVectorizer(ngram_range = (1,2))),\n",
    "        ('nb', sklearn.naive_bayes.MultinomialNB())])\n",
    "    )\n",
    "\n",
    "    , ('classifierBNB', pipefactory.create_pipe([    \n",
    "        ('vectorizer_tfidf', sklearn.feature_extraction.text.TfidfVectorizer(ngram_range = (1,2))),\n",
    "        ('bnb', sklearn.naive_bayes.BernoulliNB())])\n",
    "    )\n",
    "    \n",
    "    # Nearest Neighboars\n",
    "    , ('classifier_kNN', pipefactory.create_pipe([\n",
    "        ('vectorizer_tfidf', sklearn.feature_extraction.text.TfidfVectorizer(ngram_range = (1,2))),\n",
    "        ('kNN', sklearn.neighbors.KNeighborsClassifier(n_jobs=-1))]) # http://scikit-learn.org/stable/modules/neighbors.html#neighbors\n",
    "    )\n",
    "    # 2 Ensamble methods\n",
    "    , ('classifierRF', pipefactory.create_pipe([    \n",
    "        ('vectorizer_tfidf', sklearn.feature_extraction.text.TfidfVectorizer(ngram_range = (1,2))),\n",
    "        ('rfc', sklearn.ensemble.RandomForestClassifier(n_estimators=10, n_jobs=-1, random_state = 5152))])\n",
    "    )\n",
    "    , ('classifierADC', pipefactory.create_pipe([    \n",
    "        ('vectorizer_tfidf', sklearn.feature_extraction.text.TfidfVectorizer(ngram_range = (1,2))),\n",
    "        ('adc', sklearn.ensemble.AdaBoostClassifier(random_state = 5152))])\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.743168455617\n"
     ]
    }
   ],
   "source": [
    "pipe = pipefactory.create_pipe([\n",
    "        ('smileys', csstransformer.SmileyTransformer()),\n",
    "        #('vectorizer_tfidf', sklearn.feature_extraction.text.TfidfVectorizer(ngram_range = (1,1),stop_words=None)),\n",
    "        ('vectorizer_tfidf', sklearn.feature_extraction.text.TfidfVectorizer(ngram_range = (1,1),vocabulary=csstransformer.SmileyTransformer.smileys, stop_words=None)),\n",
    "        ('rfc', sklearn.ensemble.RandomForestClassifier(n_estimators=10, n_jobs=-1, random_state = 5152))\n",
    "        #('nb', sklearn.naive_bayes.MultinomialNB())\n",
    "    ])\n",
    "data = csshelper.COpnReader(sqlite_connection).get_results()\n",
    "\n",
    "feature = data.sentence\n",
    "label = data.cOpn\n",
    "\n",
    "#print(csstransformer.SmileyTransformer().transform(label))\n",
    "#print(csstransformer.NounTransformer().transform(label))\n",
    "\n",
    "smiley_feature = csstransformer.SmileyTransformer().transform(feature)\n",
    "\n",
    "tfidf = sklearn.feature_extraction.text.TfidfVectorizer(ngram_range = (1,1),vocabulary=['<3',':D'], stop_words=None).fit(smiley_feature, label)\n",
    "\n",
    "x = tfidf.transform(smiley_feature)\n",
    "\n",
    "#print(x)\n",
    "#print(x.toarray())\n",
    "\n",
    "#print(smiley_feature)\n",
    "\n",
    "print(sklearn.cross_validation.cross_val_score(pipe, feature, label, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cExt\n",
      "\t\u001b[1mclassifierLinearSVC\u001b[0m\n",
      "\t0.536754550778\n",
      "\n",
      "\t\u001b[1mclassifierSVC\u001b[0m\n",
      "\t0.575476428676\n",
      "\n",
      "\t\u001b[1mclassifierNB\u001b[0m\n",
      "\t0.567914114733\n",
      "\n",
      "\t\u001b[1mclassifierBNB\u001b[0m\n",
      "\t0.570635380574\n",
      "\n",
      "\t\u001b[1mclassifier_kNN\u001b[0m\n",
      "\t0.522639868316\n",
      "\n",
      "\t\u001b[1mclassifierRF\u001b[0m\n",
      "\t0.542096733525\n",
      "\n",
      "\t\u001b[1mclassifierADC\u001b[0m\n",
      "\t0.557426431116\n",
      "\n",
      "sExt\n",
      "\t\u001b[1mclassifierLinearSVC\u001b[0m\n",
      "\t0.328326286405\n",
      "\n",
      "\t\u001b[1mclassifierSVC\u001b[0m\n",
      "\t0.395281015634\n",
      "\n",
      "\t\u001b[1mclassifierNB\u001b[0m\n",
      "\t0.394474613473\n",
      "\n",
      "\t\u001b[1mclassifierBNB\u001b[0m\n",
      "\t0.390741775888\n",
      "\n",
      "\t\u001b[1mclassifier_kNN\u001b[0m\n",
      "\t0.304139635243\n",
      "\n",
      "\t\u001b[1mclassifierRF\u001b[0m\n",
      "\t0.33750465972\n",
      "\n",
      "\t\u001b[1mclassifierADC\u001b[0m\n",
      "\t0.386204668768\n",
      "\n",
      "cNeu\n",
      "\t\u001b[1mclassifierLinearSVC\u001b[0m\n",
      "\t0.555309698974\n",
      "\n",
      "\t\u001b[1mclassifierSVC\u001b[0m\n",
      "\t0.625189107413\n",
      "\n",
      "\t\u001b[1mclassifierNB\u001b[0m\n",
      "\t0.623575492493\n",
      "\n",
      "\t\u001b[1mclassifierBNB\u001b[0m\n",
      "\t0.624583709515\n",
      "\n",
      "\t\u001b[1mclassifier_kNN\u001b[0m\n",
      "\t0.42079464765\n",
      "\n",
      "\t\u001b[1mclassifierRF\u001b[0m\n",
      "\t0.597860188619\n",
      "\n",
      "\t\u001b[1mclassifierADC\u001b[0m\n",
      "\t0.606735934882\n",
      "\n",
      "sNeu\n",
      "\t\u001b[1mclassifierLinearSVC\u001b[0m\n",
      "\t0.3873122817\n",
      "\n",
      "\t\u001b[1mclassifierSVC\u001b[0m\n",
      "\t0.485126646645\n",
      "\n",
      "\t\u001b[1mclassifierNB\u001b[0m\n",
      "\t0.485126188973\n",
      "\n",
      "\t\u001b[1mclassifierBNB\u001b[0m\n",
      "\t0.485429269598\n",
      "\n",
      "\t\u001b[1mclassifier_kNN\u001b[0m\n",
      "\t0.298991166445\n",
      "\n",
      "\t\u001b[1mclassifierRF\u001b[0m\n",
      "\t0.424926367862\n",
      "\n",
      "\t\u001b[1mclassifierADC\u001b[0m\n",
      "\t0.469598025502\n",
      "\n",
      "cAgr\n",
      "\t\u001b[1mclassifierLinearSVC\u001b[0m\n",
      "\t0.513359930889\n",
      "\n",
      "\t\u001b[1mclassifierSVC\u001b[0m\n",
      "\t0.531209029908\n",
      "\n",
      "\t\u001b[1mclassifierNB\u001b[0m\n",
      "\t0.52546123076\n",
      "\n",
      "\t\u001b[1mclassifierBNB\u001b[0m\n",
      "\t0.524053042778\n",
      "\n",
      "\t\u001b[1mclassifier_kNN\u001b[0m\n",
      "\t0.471918767215\n",
      "\n",
      "\t\u001b[1mclassifierRF\u001b[0m\n",
      "\t0.506003654421\n",
      "\n",
      "\t\u001b[1mclassifierADC\u001b[0m\n",
      "\t0.511854648716\n",
      "\n",
      "sAgr\n",
      "\t\u001b[1mclassifierLinearSVC\u001b[0m\n",
      "\t0.440250600365\n",
      "\n",
      "\t\u001b[1mclassifierSVC\u001b[0m\n",
      "\t0.501966566127\n",
      "\n",
      "\t\u001b[1mclassifierNB\u001b[0m\n",
      "\t0.499545836376\n",
      "\n",
      "\t\u001b[1mclassifierBNB\u001b[0m\n",
      "\t0.499344376747\n",
      "\n",
      "\t\u001b[1mclassifier_kNN\u001b[0m\n",
      "\t0.374246404903\n",
      "\n",
      "\t\u001b[1mclassifierRF\u001b[0m\n",
      "\t0.454672743343\n",
      "\n",
      "\t\u001b[1mclassifierADC\u001b[0m\n",
      "\t0.466880804378\n",
      "\n",
      "cCon\n",
      "\t\u001b[1mclassifierLinearSVC\u001b[0m\n",
      "\t0.528283406436\n",
      "\n",
      "\t\u001b[1mclassifierSVC\u001b[0m\n",
      "\t0.540586877629\n",
      "\n",
      "\t\u001b[1mclassifierNB\u001b[0m\n",
      "\t0.542702340169\n",
      "\n",
      "\t\u001b[1mclassifierBNB\u001b[0m\n",
      "\t0.539375878849\n",
      "\n",
      "\t\u001b[1mclassifier_kNN\u001b[0m\n",
      "\t0.512351918257\n",
      "\n",
      "\t\u001b[1mclassifierRF\u001b[0m\n",
      "\t0.529289032342\n",
      "\n",
      "\t\u001b[1mclassifierADC\u001b[0m\n",
      "\t0.53282340702\n",
      "\n",
      "sCon\n",
      "\t\u001b[1mclassifierLinearSVC\u001b[0m\n",
      "\t0.45245097952\n",
      "\n",
      "\t\u001b[1mclassifierSVC\u001b[0m\n",
      "\t0.546334866369\n",
      "\n",
      "\t\u001b[1mclassifierNB\u001b[0m\n",
      "\t0.546334866369\n",
      "\n",
      "\t\u001b[1mclassifierBNB\u001b[0m\n",
      "\t0.545628966364\n",
      "\n",
      "\t\u001b[1mclassifier_kNN\u001b[0m\n",
      "\t0.31041381792\n",
      "\n",
      "\t\u001b[1mclassifierRF\u001b[0m\n",
      "\t0.486134295963\n",
      "\n",
      "\t\u001b[1mclassifierADC\u001b[0m\n",
      "\t0.541293421001\n",
      "\n",
      "cOpn\n",
      "\t\u001b[1mclassifierLinearSVC\u001b[0m\n",
      "\t0.681657038456\n",
      "\n",
      "\t\u001b[1mclassifierSVC\u001b[0m\n",
      "\t0.743168342199\n",
      "\n",
      "\t\u001b[1mclassifierNB\u001b[0m\n",
      "\t0.743571771347\n",
      "\n",
      "\t\u001b[1mclassifierBNB\u001b[0m\n",
      "\t0.742966475119\n",
      "\n",
      "\t\u001b[1mclassifier_kNN\u001b[0m\n",
      "\t0.671575427423\n",
      "\n",
      "\t\u001b[1mclassifierRF\u001b[0m\n",
      "\t0.704849893449\n",
      "\n",
      "\t\u001b[1mclassifierADC\u001b[0m\n",
      "\t0.706562840597\n",
      "\n",
      "sOpn\n",
      "\t\u001b[1mclassifierLinearSVC\u001b[0m\n",
      "\t0.572548316218\n",
      "\n",
      "\t\u001b[1mclassifierSVC\u001b[0m\n",
      "\t0.639911625684\n",
      "\n",
      "\t\u001b[1mclassifierNB\u001b[0m\n",
      "\t0.640315258379\n",
      "\n",
      "\t\u001b[1mclassifierBNB\u001b[0m\n",
      "\t0.640416217592\n",
      "\n",
      "\t\u001b[1mclassifier_kNN\u001b[0m\n",
      "\t0.539595501057\n",
      "\n",
      "\t\u001b[1mclassifierRF\u001b[0m\n",
      "\t0.603911851745\n",
      "\n",
      "\t\u001b[1mclassifierADC\u001b[0m\n",
      "\t0.629526468876\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Pipelineing\n",
    "# http://scikit-learn.org/stable/modules/pipeline.html\n",
    "# http://zacstewart.com/2014/08/05/pipelines-of-featureunions-of-pipelines.html\n",
    "\n",
    "raw_pipeline = pipefactory.create_pipe([\n",
    "        #tfidf_vectorizer\n",
    "        ('tfidf', sklearn.feature_extraction.text.TfidfVectorizer(ngram_range=(2,3), analyzer='word'))\n",
    "        #, ('kNN', sklearn.neighbors.KNeighborsClassifier())\n",
    "        , multinomial_nb\n",
    "    ])\n",
    "\n",
    "pos_pipeline = pipefactory.create_pipe([\n",
    "        #tfidf_vectorizer\n",
    "        #('part of speech', Test())\n",
    "        #('part of speech', csstransformer.PartOfSpeech(ignore_unknown=True))\n",
    "        ('part of speech', csstransformer.NounTransformer())\n",
    "        #, ('count vectorizer', sklearn.feature_extraction.text.CountVectorizer(ngram_range=(1,1)))\n",
    "        , ('tfidf', sklearn.feature_extraction.text.TfidfVectorizer(ngram_range=(2,3), analyzer='word'))\n",
    "        #, ('k_best', sklearn.feature_selection.SelectKBest(sklearn.feature_selection.chi2, k=1000))\n",
    "        #, ('kNN', sklearn.neighbors.KNeighborsClassifier())\n",
    "        , multinomial_nb\n",
    "    ])\n",
    "\n",
    "\n",
    "for feature_name, reader in data_reader_collection:\n",
    "    print(feature_name)\n",
    "    \n",
    "    data = reader.get_results()\n",
    "    \n",
    "    label = data.iloc[:,0]\n",
    "    feature = data.iloc[:,1]\n",
    "    \n",
    "    for pipe_name, pipeline in pipeline_collection:\n",
    "        print(\"\\t\\033[1m%s\\033[0m\" % pipe_name)\n",
    "        acc = sklearn.cross_validation.cross_val_score(pipeline, label, feature, cv=5)\n",
    "        print(\"\\t%s\" % acc.mean())\n",
    "        print()\n",
    "        pass\n",
    "    \n",
    "    #r1 = sklearn.cross_validation.cross_val_score(raw_pipeline, label, feature, cv=5)\n",
    "    #r2 = sklearn.cross_validation.cross_val_score(pos_pipeline, label, feature, cv=5)\n",
    "\n",
    "    #print(r1.mean())\n",
    "    #print(r2.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data:\n",
      "['likes the sound of thunder.'\n",
      " \"is so sleepy it's not even funny that's she can't get to sleep.\"\n",
      " \"is sore and wants the knot of muscles at the base of her neck to stop hurting. On the other hand, YAY I'M IN ILLINOIS! <3\"]\n",
      "['and', 'and wants', 'at', 'at the', 'base', 'base of', 'can', 'can get', 'even', 'even funny']\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "test_data = data['sentence'].astype(str).values[:3]\n",
    "\n",
    "print(\"test_data:\\n%s\" % test_data)\n",
    "\n",
    "tfidf_trans = sklearn.feature_extraction.text.TfidfVectorizer(ngram_range=(1,2))\n",
    "#help(tfidf_trans)\n",
    "tfidf_trans.fit(test_data)\n",
    "#tfidf_trans.transform(test_data)\n",
    "\n",
    "print(tfidf_trans.get_feature_names()[:10])\n",
    "\n",
    "type(tfidf_trans.transform(data))\n",
    "print(tfidf_trans.transform([\"funny\", \"and\"]).toarray())\n",
    "\n",
    "#tfidf_trans.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "False\n",
      "select_k has transform: True\n",
      "select_k has fit: True\n",
      "select_k has fit_transform: True\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = sklearn.feature_extraction.text.TfidfVectorizer()\n",
    "\n",
    "pipeline = sklearn.pipeline.Pipeline([('tfidf', tfidf_vectorizer),\n",
    "                     ('k_best', sklearn.feature_selection.SelectKBest(sklearn.feature_selection.chi2, k=1000)),\n",
    "                     ('nb', sklearn.naive_bayes.MultinomialNB())\n",
    "                    ])\n",
    "\n",
    "#pipeline.fit(train_feat[[\"STATUS\"]], train_label[[\"cNEU\"]])\n",
    "#data = train_feat.STATUS\n",
    "#target = train_label.cNEU.apply(lambda x: x == 'y')\n",
    "\n",
    "#foo = tfidf_vectorizer.fit_transform(data[:1], target[:1])\n",
    "#print(foo)\n",
    "#idf = foo.idf_\n",
    "\n",
    "#print(len(idf))\n",
    "#print(len(data))\n",
    "\n",
    "#pipeline.fit(data.sentence, data.cNeu)\n",
    "import sklearn\n",
    "import sklearn.feature_extraction.text\n",
    "\n",
    "data = csshelper.CNeuReader(sqlite_connection).get_results()\n",
    "\n",
    "features = data.sentence\n",
    "labels = data.cNeu\n",
    "\n",
    "cv = sklearn.feature_extraction.text.CountVectorizer()\n",
    "\n",
    "cv_fit = cv.fit(features, labels)\n",
    "cv_transform_features = cv_fit.transform(features)\n",
    "\n",
    "\n",
    "tfidftrans = sklearn.feature_extraction.text.TfidfTransformer()\n",
    "\n",
    "tfidftrans_fit = tfidftrans.fit(cv_transform_features, labels)\n",
    "tfidftrans_transform_features = tfidftrans_fit.transform(cv_transform_features)\n",
    "\n",
    "#print(cv_transform_features)\n",
    "#print(tfidftrans_transform_features)\n",
    "\n",
    "skb = sklearn.feature_selection.SelectKBest(sklearn.feature_selection.chi2, k=1000)\n",
    "mnb = sklearn.naive_bayes.MultinomialNB()\n",
    "\n",
    "\n",
    "\n",
    "mnb_fit = mnb.fit(tfidftrans_transform_features, labels.astype(bool))\n",
    "\n",
    "print(hasattr(mnb_fit, \"fit\"))\n",
    "print(hasattr(mnb_fit, \"transform\"))\n",
    "print(hasattr(mnb_fit, \"fit_transform\"))\n",
    "\n",
    "pipe = sklearn.pipeline.Pipeline([\n",
    "    ('cv', sklearn.feature_extraction.text.CountVectorizer())\n",
    "    , ('tfidf_trans', sklearn.feature_extraction.text.TfidfTransformer())\n",
    "    , ('nb', sklearn.naive_bayes.MultinomialNB())\n",
    "])\n",
    "\n",
    "sklearn.cross_validation.cross_val_score(pipe, features.astype(str), labels.astype(bool))\n",
    "\n",
    "\n",
    "\n",
    "#print(tfidf_vectorizer.fit_transform(features, labels))\n",
    "#tfidf = tfidf_vectorizer.fit_transform(features, labels)\n",
    "#print(tfidf)\n",
    "\n",
    "#print(tfidf[[9]])\n",
    "\n",
    "\n",
    "select_k = sklearn.feature_selection.SelectKBest(sklearn.feature_selection.chi2, k=1000)\n",
    "print('select_k has transform: %s' % hasattr(select_k, 'transform'))\n",
    "print('select_k has fit: %s' % hasattr(select_k, 'fit'))\n",
    "print('select_k has fit_transform: %s' % hasattr(select_k, 'fit_transform'))\n",
    "\n",
    "\n",
    "#help(tfidf_vectorizer)\n",
    "\n",
    "#result = sk.cross_validation.cross_val_score(pipeline, data[[0]], data[[1]])\n",
    "\n",
    "#print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe_factory = csspipe.PipeFactory()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf_nb_pipe = pipe_factory.create_tfidf_nb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "         ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "         stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "         token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "         vocabulary=None))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_nb_pipe.steps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-71feb5ebd4a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_validation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfidf_nb_pipe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/sklearn/cross_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[0;32m   1431\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1432\u001b[0m                                               fit_params)\n\u001b[1;32m-> 1433\u001b[1;33m                       for train, test in cv)\n\u001b[0m\u001b[0;32m   1434\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    802\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    803\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 804\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    805\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    660\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 662\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    663\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    664\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 570\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateComputeBatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/sklearn/cross_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, error_score)\u001b[0m\n\u001b[0;32m   1529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1530\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1531\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1533\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    162\u001b[0m             \u001b[0mthe\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m         \"\"\"\n\u001b[1;32m--> 164\u001b[1;33m         \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pre_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_pre_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"fit_transform\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m                 \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m                 \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1303\u001b[0m             \u001b[0mTf\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0midf\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mweighted\u001b[0m \u001b[0mdocument\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mterm\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m         \"\"\"\n\u001b[1;32m-> 1305\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1306\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1307\u001b[0m         \u001b[1;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m    815\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[1;32m--> 817\u001b[1;33m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    819\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m    750\u001b[0m         \u001b[0mindptr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    751\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 752\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    753\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    754\u001b[0m                     \u001b[0mj_indices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(doc)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m             return lambda doc: self._word_ngrams(\n\u001b[1;32m--> 238\u001b[1;33m                 tokenize(preprocess(self.decode(doc))), stop_words)\n\u001b[0m\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlowercase\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstrip_accents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mstrip_accents\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "result = sklearn.cross_validation.cross_val_score(tfidf_nb_pipe, data[[0]].values, data[[1]].values)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
