{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy\n",
    "import pandas\n",
    "import sklearn\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "import csshelper\n",
    "import cssfeature\n",
    "import csspipe\n",
    "import csstransformer\n",
    "\n",
    "db_path = './data.sqlite3'\n",
    "sqlite_connection = sqlite3.connect(db_path)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_reader_collection = [\n",
    "        ('cExt', csshelper.CExtReader(sqlite_connection))\n",
    "    \n",
    "        , ('cNeu', csshelper.CNeuReader(sqlite_connection))\n",
    "     \n",
    "        , ('cAgr', csshelper.CAgrReader(sqlite_connection))\n",
    "    \n",
    "        , ('cCon', csshelper.CConReader(sqlite_connection))\n",
    "    \n",
    "        , ('cOpn', csshelper.COpnReader(sqlite_connection)) \n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'token' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-54178f87956d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsshelper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCExtReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msqlite_connection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0maggregator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/dust/workspace/CaseSolvingSeminar/src/csstransformer/aggregator.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, series)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mtseries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransformers\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtseries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dust/workspace/CaseSolvingSeminar/src/csstransformer/aggregator.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mtseries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransformers\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtseries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dust/workspace/CaseSolvingSeminar/src/csstransformer/averagewordlength.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, series)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mcpy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mseries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         cpy = cpy.apply(\n\u001b[1;32m---> 16\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_calculate_average_word_length\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         )\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.4/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   2167\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTimestamp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2169\u001b[1;33m         \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2170\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2171\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframe\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/src/inference.pyx\u001b[0m in \u001b[0;36mpandas.lib.map_infer (pandas/lib.c:62588)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m/home/dust/workspace/CaseSolvingSeminar/src/csstransformer/averagewordlength.py\u001b[0m in \u001b[0;36m_calculate_average_word_length\u001b[1;34m(self, sentence)\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mavg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mavg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'token' is not defined"
     ]
    }
   ],
   "source": [
    "aggregator = csstransformer.Aggregator([\n",
    "        csstransformer.PartOfSpeech(),\n",
    "        csstransformer.SentenceLength(),\n",
    "        #csstransformer.NumberOfWords(),\n",
    "        csstransformer.NumberOfCommas(),\n",
    "        csstransformer.NumberOfDots(),\n",
    "        csstransformer.NumberOfSemicolons(),\n",
    "        csstransformer.NumberOfColons(),\n",
    "        csstransformer.LexicalDiversity(),\n",
    "        csstransformer.AverageWordLength(),\n",
    "        csstransformer.NumberOfFunctionalWords(),\n",
    "        csstransformer.NumberOfPronouns(),\n",
    "        csstransformer.NumberOfPropnames(),\n",
    "])\n",
    "\n",
    "data = csshelper.CExtReader(sqlite_connection).get_results()\n",
    "\n",
    "aggregator.transform(data.sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'PartOfSpeechTransformer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-680eb2afa832>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m pipeline = sklearn.pipeline.Pipeline([\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;33m(\u001b[0m\u001b[1;34m'Parto of Speech'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcsstransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPartOfSpeechTransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[1;34m'vect'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[1;34m'cier'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5152\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m ])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'module' object has no attribute 'PartOfSpeechTransformer'"
     ]
    }
   ],
   "source": [
    "pipeline = sklearn.pipeline.Pipeline([\n",
    "    ('Parto of Speech', csstransformer.PartOfSpeechTransformer()),\n",
    "    ('vect', sklearn.feature_extraction.text.TfidfVectorizer()),\n",
    "    ('cier', sklearn.ensemble.RandomForestClassifier(random_state = 5152))\n",
    "])\n",
    "\n",
    "fu([\n",
    "        pipeline([\n",
    "                csstransformer.PartOfSpeechTransformer(),\n",
    "            ]),\n",
    "        pipeline([\n",
    "                csstransformer.SentenceLenght(),\n",
    "            ])\n",
    "    ])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for reader_description, reader in data_reader_collection:\n",
    "    data = reader.get_result()\n",
    "    \n",
    "    label = data.iloc[:,0]\n",
    "    feature = data.iloc[:,1]\n",
    "    \n",
    "    split = sk.cross_validation.train_test_split(data, data[reader_description], train_size=0.66, \n",
    "                                                 stratify=data[reader_description],random_state=5152)\n",
    "    x_train, x_test, y_train, y_test = split\n",
    "    \n",
    "    \n",
    "    \n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split = sk.cross_validation.train_test_split(neu, neu[\"cNEU\"], train_size = 0.66, stratify = neu[\"cNEU\"],random_state= 5152)\n",
    "train_feat_neu, test_feat_neu, train_class_neu, test_class_neu  = split\n",
    "print(train_feat_neu.shape, test_feat_neu.shape,train_class_neu.shape ,test_class_neu.shape)\n",
    "\n",
    "neu_X = train_feat_neu.append(test_feat_neu)\n",
    "neu_Y = train_class_neu.append(test_class_neu)\n",
    "\n",
    "train_feat_ext, test_feat_ext, train_class_ext, test_class_ext = sk.cross_validation.train_test_split(ext, ext[\"cEXT\"], train_size = 0.66, stratify = ext[\"cEXT\"],random_state= 5152)\n",
    "\n",
    "ext_X = train_feat_ext.append(test_feat_ext)\n",
    "ext_Y = train_class_ext.append(test_class_ext)\n",
    "\n",
    "train_feat_agr, test_feat_agr, train_class_agr, test_class_agr = sk.cross_validation.train_test_split(agr, agr[\"cAGR\"], train_size = 0.66, stratify = agr[\"cAGR\"],random_state= 5152)\n",
    "\n",
    "agr_X = train_feat_agr.append(test_feat_agr)\n",
    "agr_Y = train_class_agr.append(test_class_agr)\n",
    "\n",
    "train_feat_con, test_feat_con, train_class_con, test_class_con = sk.cross_validation.train_test_split(con, con[\"cCON\"], train_size = 0.66, stratify = con[\"cCON\"],random_state= 5152)\n",
    "\n",
    "con_X = train_feat_con.append(test_feat_con)\n",
    "con_Y = train_class_con.append(test_class_con)\n",
    "\n",
    "train_feat_opn, test_feat_opn, train_class_opn, test_class_opn = sk.cross_validation.train_test_split(opn, opn[\"cOPN\"], train_size = 0.66, stratify = opn[\"cOPN\"],random_state= 5152)\n",
    "\n",
    "opn_X = train_feat_opn.append(test_feat_opn)\n",
    "opn_Y = train_class_opn.append(test_class_opn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package csstransformer:\n",
      "\n",
      "NAME\n",
      "    csstransformer - # helpers\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    aggregator\n",
      "    basetransformer\n",
      "    lexicaldiversity\n",
      "    nountransformer\n",
      "    numberofdots\n",
      "    partofspeech\n",
      "    sentencelength\n",
      "    smiley\n",
      "    stemmedwords\n",
      "    stemmer\n",
      "    tagging\n",
      "    tokenizer\n",
      "\n",
      "FILE\n",
      "    /home/dust/workspace/CaseSolvingSeminar/src/csstransformer/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(csstransformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
