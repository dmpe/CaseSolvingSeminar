{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy\n",
    "import pandas\n",
    "import sklearn\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "import csshelper\n",
    "import cssfeature\n",
    "import csspipe\n",
    "import csstransformer\n",
    "\n",
    "db_path = './data.sqlite3'\n",
    "sqlite_connection = sqlite3.connect(db_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_reader_collection = [\n",
    "        ('cExt', csshelper.CExtReader(sqlite_connection))\n",
    "        , ('sExt', csshelper.SExtReader(sqlite_connection))\n",
    "    \n",
    "        , ('cNeu', csshelper.CNeuReader(sqlite_connection))\n",
    "        , ('sNeu', csshelper.SNeuReader(sqlite_connection))\n",
    "     \n",
    "        , ('cAgr', csshelper.CAgrReader(sqlite_connection))\n",
    "        , ('sAgr', csshelper.SAgrReader(sqlite_connection))\n",
    "    \n",
    "        , ('cCon', csshelper.CConReader(sqlite_connection))\n",
    "        , ('sCon', csshelper.SConReader(sqlite_connection))\n",
    "    \n",
    "        , ('cOpn', csshelper.COpnReader(sqlite_connection))\n",
    "        , ('sOpn', csshelper.SOpnReader(sqlite_connection))   \n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline = sklearn.pipeline.Pipeline([\n",
    "    ('Parto of Speech', csstransformer.PartOfSpeechTransformer()),\n",
    "    ('vect', sklearn.feature_extraction.text.TfidfVectorizer()),\n",
    "    ('cier', sklearn.ensemble.RandomForestClassifier(random_state = 5152))\n",
    "])\n",
    "\n",
    "fu([\n",
    "        pipeline([\n",
    "                csstransformer.PartOfSpeechTransformer(),\n",
    "            ]),\n",
    "        pipeline([\n",
    "                csstransformer.SentenceLenght(),\n",
    "            ])\n",
    "    ])\n",
    "\n",
    "\n",
    "\n",
    "TransformerAggregator([csstrasformer.PartOfSpeechTransformer(), csstransformer.SentenceLengthTransformer()])\n",
    "\n",
    "class TransformerAggregator(object):\n",
    "    \n",
    "    def __init__(self, transformators):\n",
    "        self.transformators = transformators\n",
    "    \n",
    "    def transform(self, pandas_series):\n",
    "        df = pandas.DataFrame()\n",
    "        \n",
    "        # execute each self.transformer. append to df\n",
    "        \n",
    "        \n",
    "        return df\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for reader_description, reader in data_reader_collection:\n",
    "    data = reader.get_result()\n",
    "    \n",
    "    label = data.iloc[:,0]\n",
    "    feature = data.iloc[:,1]\n",
    "    \n",
    "    split = sk.cross_validation.train_test_split(data, data[reader_description], train_size=0.66, \n",
    "                                                 stratify=data[reader_description],random_state=5152)\n",
    "    x_train, x_test, y_train, y_test = split\n",
    "    \n",
    "    \n",
    "    \n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split = sk.cross_validation.train_test_split(neu, neu[\"cNEU\"], train_size = 0.66, stratify = neu[\"cNEU\"],random_state= 5152)\n",
    "train_feat_neu, test_feat_neu, train_class_neu, test_class_neu  = split\n",
    "print(train_feat_neu.shape, test_feat_neu.shape,train_class_neu.shape ,test_class_neu.shape)\n",
    "\n",
    "neu_X = train_feat_neu.append(test_feat_neu)\n",
    "neu_Y = train_class_neu.append(test_class_neu)\n",
    "\n",
    "train_feat_ext, test_feat_ext, train_class_ext, test_class_ext = sk.cross_validation.train_test_split(ext, ext[\"cEXT\"], train_size = 0.66, stratify = ext[\"cEXT\"],random_state= 5152)\n",
    "\n",
    "ext_X = train_feat_ext.append(test_feat_ext)\n",
    "ext_Y = train_class_ext.append(test_class_ext)\n",
    "\n",
    "train_feat_agr, test_feat_agr, train_class_agr, test_class_agr = sk.cross_validation.train_test_split(agr, agr[\"cAGR\"], train_size = 0.66, stratify = agr[\"cAGR\"],random_state= 5152)\n",
    "\n",
    "agr_X = train_feat_agr.append(test_feat_agr)\n",
    "agr_Y = train_class_agr.append(test_class_agr)\n",
    "\n",
    "train_feat_con, test_feat_con, train_class_con, test_class_con = sk.cross_validation.train_test_split(con, con[\"cCON\"], train_size = 0.66, stratify = con[\"cCON\"],random_state= 5152)\n",
    "\n",
    "con_X = train_feat_con.append(test_feat_con)\n",
    "con_Y = train_class_con.append(test_class_con)\n",
    "\n",
    "train_feat_opn, test_feat_opn, train_class_opn, test_class_opn = sk.cross_validation.train_test_split(opn, opn[\"cOPN\"], train_size = 0.66, stratify = opn[\"cOPN\"],random_state= 5152)\n",
    "\n",
    "opn_X = train_feat_opn.append(test_feat_opn)\n",
    "opn_Y = train_class_opn.append(test_class_opn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
