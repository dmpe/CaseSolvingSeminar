{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cython extension is already loaded. To reload it, use:\n",
      "  %reload_ext cython\n",
      "The cythonmagic extension is already loaded. To reload it, use:\n",
      "  %reload_ext cythonmagic\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, reprlib, sys\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import *\n",
    "import random as ran\n",
    "from logging import *\n",
    "from pprint import *\n",
    "from time import *\n",
    "import shlex, subprocess\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "\n",
    "%load_ext cython\n",
    "%load_ext cythonmagic\n",
    "%matplotlib inline\n",
    "%matplotlib notebook\n",
    "\n",
    "from pandas_confusion import *\n",
    "from scipy.cluster.vq import *\n",
    "\n",
    "import nltk as n\n",
    "import nltk, nltk.classify.util, nltk.metrics, nltk.tokenize, nltk.stem\n",
    "from nltk.corpus import *\n",
    "from nltk.stem import *\n",
    "from nltk.classify import *\n",
    "from nltk.collocations import *\n",
    "from nltk.metrics import BigramAssocMeasures as BAM\n",
    "from nltk.probability import *\n",
    "from nltk.classify.scikitlearn import *\n",
    "from nltk.tag.sequential import *\n",
    "from nltk.tag import *\n",
    "from nltk.tag.util import *\n",
    "# n.download()\n",
    "\n",
    "from sklearn_pandas import *\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn import *\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.svm import *\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.cross_validation import *\n",
    "from sklearn.pipeline import *\n",
    "from sklearn.multiclass import *\n",
    "from sklearn.datasets import *\n",
    "from sklearn.naive_bayes import *\n",
    "from sklearn.neighbors import *\n",
    "from sklearn.feature_selection import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.tree import *\n",
    "from sklearn.grid_search import *\n",
    "from sklearn.base import *\n",
    "from sklearn.datasets.twenty_newsgroups import *\n",
    "from sklearn.decomposition import *\n",
    "from sklearn.feature_extraction import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.utils import *\n",
    "\n",
    "sk.utils.check_random_state(5125)\n",
    "ran.seed(5125)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R script adding new features to dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# http://www.mango-solutions.com/wp/2015/10/integrating-python-and-r-part-ii-executing-r-from-python-and-vice-versa/\n",
    "command = 'Rscript'\n",
    "path2script = 'insert_features.R'\n",
    "\n",
    "# Build subprocess command\n",
    "cmd = [command, path2script]\n",
    "\n",
    "subprocess.check_output(cmd, universal_newlines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>#AUTHID</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>sEXT</th>\n",
       "      <th>sNEU</th>\n",
       "      <th>sAGR</th>\n",
       "      <th>sCON</th>\n",
       "      <th>sOPN</th>\n",
       "      <th>cEXT</th>\n",
       "      <th>cNEU</th>\n",
       "      <th>...</th>\n",
       "      <th>Number_of_Semicolons</th>\n",
       "      <th>Number_of_Colons</th>\n",
       "      <th>Average_Word_Length</th>\n",
       "      <th>POS_sentiment</th>\n",
       "      <th>NEG_sentiment</th>\n",
       "      <th>OverAll_sentiment</th>\n",
       "      <th>Lexical_Diversity</th>\n",
       "      <th>Number_of_FunctionalWords</th>\n",
       "      <th>Number_of_Pronouns</th>\n",
       "      <th>Number_of_PROPNAMEs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
       "      <td>likes the sound of thunder.</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.4</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.700</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
       "      <td>is so sleepy it's not even funny that's she ca...</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.4</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.615</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.577</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
       "      <td>is sore and wants the knot of muscles at the b...</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.4</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.500</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0.509</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
       "      <td>likes how the day sounds in this new song.</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.4</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.611</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
       "      <td>is home. &lt;3</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.4</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.857</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                           #AUTHID  \\\n",
       "0           1  b7b7764cfa1c523e4e93ab2a79a946c4   \n",
       "1           2  b7b7764cfa1c523e4e93ab2a79a946c4   \n",
       "2           3  b7b7764cfa1c523e4e93ab2a79a946c4   \n",
       "3           4  b7b7764cfa1c523e4e93ab2a79a946c4   \n",
       "4           5  b7b7764cfa1c523e4e93ab2a79a946c4   \n",
       "\n",
       "                                              STATUS  sEXT  sNEU  sAGR  sCON  \\\n",
       "0                        likes the sound of thunder.  2.65     3  3.15  3.25   \n",
       "1  is so sleepy it's not even funny that's she ca...  2.65     3  3.15  3.25   \n",
       "2  is sore and wants the knot of muscles at the b...  2.65     3  3.15  3.25   \n",
       "3         likes how the day sounds in this new song.  2.65     3  3.15  3.25   \n",
       "4                                        is home. <3  2.65     3  3.15  3.25   \n",
       "\n",
       "   sOPN cEXT cNEU         ...          Number_of_Semicolons Number_of_Colons  \\\n",
       "0   4.4    n    y         ...                             0                0   \n",
       "1   4.4    n    y         ...                             0                0   \n",
       "2   4.4    n    y         ...                             0                0   \n",
       "3   4.4    n    y         ...                             0                0   \n",
       "4   4.4    n    y         ...                             0                0   \n",
       "\n",
       "  Average_Word_Length POS_sentiment  NEG_sentiment  OverAll_sentiment  \\\n",
       "0               4.400             0              0                  0   \n",
       "1               3.615             0              0                  0   \n",
       "2               3.500             0              2                 -2   \n",
       "3               3.667             0              0                  0   \n",
       "4               2.333             0              0                  0   \n",
       "\n",
       "   Lexical_Diversity  Number_of_FunctionalWords  Number_of_Pronouns  \\\n",
       "0              0.700                          2                   0   \n",
       "1              0.577                         10                   1   \n",
       "2              0.509                         14                   1   \n",
       "3              0.611                          4                   0   \n",
       "4              0.857                          1                   0   \n",
       "\n",
       "   Number_of_PROPNAMEs  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_n = pd.read_csv(\"../raw_data/data_n.csv\", parse_dates=True, infer_datetime_format=True)\n",
    "data_n.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace 'y' and 'n'   AND easy split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>#AUTHID</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>sEXT</th>\n",
       "      <th>sNEU</th>\n",
       "      <th>sAGR</th>\n",
       "      <th>sCON</th>\n",
       "      <th>sOPN</th>\n",
       "      <th>cEXT</th>\n",
       "      <th>cNEU</th>\n",
       "      <th>...</th>\n",
       "      <th>Number_of_Semicolons</th>\n",
       "      <th>Number_of_Colons</th>\n",
       "      <th>Average_Word_Length</th>\n",
       "      <th>POS_sentiment</th>\n",
       "      <th>NEG_sentiment</th>\n",
       "      <th>OverAll_sentiment</th>\n",
       "      <th>Lexical_Diversity</th>\n",
       "      <th>Number_of_FunctionalWords</th>\n",
       "      <th>Number_of_Pronouns</th>\n",
       "      <th>Number_of_PROPNAMEs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
       "      <td>likes the sound of thunder.</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                           #AUTHID                       STATUS  \\\n",
       "0           1  b7b7764cfa1c523e4e93ab2a79a946c4  likes the sound of thunder.   \n",
       "\n",
       "   sEXT  sNEU  sAGR  sCON  sOPN  cEXT  cNEU         ...           \\\n",
       "0  2.65     3  3.15  3.25   4.4     0     1         ...            \n",
       "\n",
       "   Number_of_Semicolons  Number_of_Colons  Average_Word_Length POS_sentiment  \\\n",
       "0                     0                 0                  4.4             0   \n",
       "\n",
       "   NEG_sentiment  OverAll_sentiment  Lexical_Diversity  \\\n",
       "0              0                  0                0.7   \n",
       "\n",
       "   Number_of_FunctionalWords  Number_of_Pronouns  Number_of_PROPNAMEs  \n",
       "0                          2                   0                    0  \n",
       "\n",
       "[1 rows x 35 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# http://stackoverflow.com/a/17702781\n",
    "d = {'n': 0, 'y': 1}\n",
    "data_n = data_n.replace(d)\n",
    "data_n.head(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#norm:http://blog.yhat.com/posts/predicting-customer-churn-with-sklearn.html\n",
    "# scaler = StandardScaler()\n",
    "# X = scaler.fit_transform(X)\n",
    "# to_drop = ['State','Area Code','Phone','Churn?']\n",
    "# churn_feat_space = data_n.drop(to_drop,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neu = data_n[[\"#AUTHID\",\"STATUS\",\"cNEU\", \"StringLength\", \n",
    "                  \"Number_of_Words\", \"Number_of_Dots\", \"Number_of_Commas\", \"Number_of_Semicolons\", \n",
    "                  \"Number_of_Colons\", \"Average_Word_Length\", \"Lexical_Diversity\"]]\n",
    "ext = data_n[[\"#AUTHID\",\"STATUS\",\"cEXT\", \"StringLength\", \n",
    "                  \"Number_of_Words\", \"Number_of_Dots\", \"Number_of_Commas\", \"Number_of_Semicolons\", \n",
    "                  \"Number_of_Colons\", \"Average_Word_Length\", \"Lexical_Diversity\"]]\n",
    "agr = data_n[[\"#AUTHID\",\"STATUS\",\"cAGR\", \"StringLength\", \n",
    "                  \"Number_of_Words\", \"Number_of_Dots\", \"Number_of_Commas\", \"Number_of_Semicolons\", \n",
    "                  \"Number_of_Colons\", \"Average_Word_Length\", \"Lexical_Diversity\"]]\n",
    "con = data_n[[\"#AUTHID\",\"STATUS\",\"cCON\", \"StringLength\", \n",
    "                  \"Number_of_Words\", \"Number_of_Dots\", \"Number_of_Commas\", \"Number_of_Semicolons\", \n",
    "                  \"Number_of_Colons\", \"Average_Word_Length\", \"Lexical_Diversity\"]]\n",
    "opn = data_n[[\"#AUTHID\",\"STATUS\",\"cOPN\", \"StringLength\", \n",
    "                  \"Number_of_Words\", \"Number_of_Dots\", \"Number_of_Commas\", \"Number_of_Semicolons\", \n",
    "                  \"Number_of_Colons\", \"Average_Word_Length\", \"Lexical_Diversity\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split stra. k-fold + selection of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# neu = data_n[[\"#AUTHID\",\"STATUS\",\"cNEU\"]]\n",
    "# train_neu, test_neu, y_train, y_test = sk.cross_validation.train_test_split(neu, neu[\"cNEU\"], train_size = 0.66, stratify= neu[\"cNEU\"])\n",
    "# train_neu, test_neu, y_train, y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6545, 11) (3372, 11) (6545,) (3372,)\n"
     ]
    }
   ],
   "source": [
    "train_feat_neu, test_feat_neu, train_class_neu, test_class_neu = sk.cross_validation.train_test_split(neu, neu[\"cNEU\"], train_size = 0.66, stratify = neu[\"cNEU\"],random_state= 5152)\n",
    "print(train_feat_neu.shape, test_feat_neu.shape,train_class_neu.shape ,test_class_neu.shape)\n",
    "\n",
    "neu_X = train_feat_neu.append(test_feat_neu)\n",
    "neu_Y = train_class_neu.append(test_class_neu)\n",
    "train_feat_ext, test_feat_ext, train_class_ext, test_class_ext = sk.cross_validation.train_test_split(ext, ext[\"cEXT\"], train_size = 0.66, stratify = ext[\"cEXT\"],random_state= 5152)\n",
    "train_feat_agr, test_feat_agr, train_class_agr, test_class_agr = sk.cross_validation.train_test_split(agr, agr[\"cAGR\"], train_size = 0.66, stratify = agr[\"cAGR\"],random_state= 5152)\n",
    "train_feat_con, test_feat_con, train_class_con, test_class_con = sk.cross_validation.train_test_split(con, con[\"cCON\"], train_size = 0.66, stratify = con[\"cCON\"],random_state= 5152)\n",
    "train_feat_opn, test_feat_opn, train_class_opn, test_class_opn = sk.cross_validation.train_test_split(opn, opn[\"cOPN\"], train_size = 0.66, stratify = opn[\"cOPN\"],random_state= 5152)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mku = sk.pipeline.make_pipeline(SGDClassifier(), LinearSVC(),\n",
    "#                                # BernoulliNB(), #MultinomialNB()\n",
    "#                                # KNeighborsClassifier(),\n",
    "#               RandomForestClassifier(n_jobs=-1),AdaBoostClassifier()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of classifiers \n",
    "with their configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = [\"ttSVC\", \"ttLinearSVC\", \"ttMNB\", \"ttBNB\", \"ttRF\", \"ttAD\", \"ttKNN\"]\n",
    "classifiers = [\n",
    "    SVC(cache_size=500, kernel = \"rbf\", decision_function_shape = \"ovr\"),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    BernoulliNB(),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1, n_jobs=-1),\n",
    "    AdaBoostClassifier(),\n",
    "    KNeighborsClassifier()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train + Test many classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "\n",
      "Predicted   0.0  1.0  __all__\n",
      "Actual                       \n",
      "0.0         558   37      595\n",
      "1.0         503   46      549\n",
      "__all__    1061   83     1144\n",
      "\n",
      "\n",
      "Overall Statistics:\n",
      "\n",
      "Accuracy: 0.527972027972\n",
      "95% CI: (0.49856611934324468, 0.55723376668452085)\n",
      "No Information Rate: ToDo\n",
      "P-Value [Acc > NIR]: 1.0\n",
      "Kappa: 0.0223367316902\n",
      "Mcnemar's Test P-Value: ToDo\n",
      "\n",
      "\n",
      "Class Statistics:\n",
      "\n",
      "Classes                                        0          1\n",
      "Population                                  1144       1144\n",
      "P: Condition positive                        595        549\n",
      "N: Condition negative                        549        595\n",
      "Test outcome positive                       1061         83\n",
      "Test outcome negative                         83       1061\n",
      "TP: True Positive                            558         46\n",
      "TN: True Negative                             46        558\n",
      "FP: False Positive                           503         37\n",
      "FN: False Negative                            37        503\n",
      "TPR: (Sensitivity, hit rate, recall)    0.937815  0.0837887\n",
      "TNR=SPC: (Specificity)                 0.0837887   0.937815\n",
      "PPV: Pos Pred Value (Precision)         0.525919   0.554217\n",
      "NPV: Neg Pred Value                     0.554217   0.525919\n",
      "FPR: False-out                          0.916211  0.0621849\n",
      "FDR: False Discovery Rate               0.474081   0.445783\n",
      "FNR: Miss Rate                         0.0621849   0.916211\n",
      "ACC: Accuracy                           0.527972   0.527972\n",
      "F1 score                                0.673913    0.14557\n",
      "MCC: Matthews correlation coefficient  0.0416082  0.0416082\n",
      "Informedness                           0.0216038  0.0216038\n",
      "Markedness                             0.0801358  0.0801358\n",
      "Prevalence                              0.520105   0.479895\n",
      "LR+: Positive likelihood ratio           1.02358    1.34741\n",
      "LR-: Negative likelihood ratio          0.742163   0.976964\n",
      "DOR: Diagnostic odds ratio               1.37918    1.37918\n",
      "FOR: False omission rate                0.445783   0.474081\n",
      "\n",
      " NEXT ttSVC \n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "Predicted  0.0   1.0  __all__\n",
      "Actual                       \n",
      "0.0         38   557      595\n",
      "1.0         25   524      549\n",
      "__all__     63  1081     1144\n",
      "\n",
      "\n",
      "Overall Statistics:\n",
      "\n",
      "Accuracy: 0.491258741259\n",
      "95% CI: (0.46190658562248371, 0.52065594876492716)\n",
      "No Information Rate: ToDo\n",
      "P-Value [Acc > NIR]: 1.0\n",
      "Kappa: 0.0176664473238\n",
      "Mcnemar's Test P-Value: ToDo\n",
      "\n",
      "\n",
      "Class Statistics:\n",
      "\n",
      "Classes                                        0          1\n",
      "Population                                  1144       1144\n",
      "P: Condition positive                        595        549\n",
      "N: Condition negative                        549        595\n",
      "Test outcome positive                         63       1081\n",
      "Test outcome negative                       1081         63\n",
      "TP: True Positive                             38        524\n",
      "TN: True Negative                            524         38\n",
      "FP: False Positive                            25        557\n",
      "FN: False Negative                           557         25\n",
      "TPR: (Sensitivity, hit rate, recall)   0.0638655   0.954463\n",
      "TNR=SPC: (Specificity)                  0.954463  0.0638655\n",
      "PPV: Pos Pred Value (Precision)         0.603175   0.484736\n",
      "NPV: Neg Pred Value                     0.484736   0.603175\n",
      "FPR: False-out                         0.0455373   0.936134\n",
      "FDR: False Discovery Rate               0.396825   0.515264\n",
      "FNR: Miss Rate                          0.936134  0.0455373\n",
      "ACC: Accuracy                           0.491259   0.491259\n",
      "F1 score                                0.115502   0.642945\n",
      "MCC: Matthews correlation coefficient  0.0401404  0.0401404\n",
      "Informedness                           0.0183282  0.0183282\n",
      "Markedness                              0.087911   0.087911\n",
      "Prevalence                              0.520105   0.479895\n",
      "LR+: Positive likelihood ratio           1.40249    1.01958\n",
      "LR-: Negative likelihood ratio          0.980797   0.713019\n",
      "DOR: Diagnostic odds ratio               1.42995    1.42995\n",
      "FOR: False omission rate                0.515264   0.396825\n",
      "\n",
      " NEXT ttLinearSVC \n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "Predicted   0.0  1.0  __all__\n",
      "Actual                       \n",
      "0.0         591    4      595\n",
      "1.0         548    1      549\n",
      "__all__    1139    5     1144\n",
      "\n",
      "\n",
      "Overall Statistics:\n",
      "\n",
      "Accuracy: 0.517482517483\n",
      "95% CI: (0.48807604286797845, 0.54679888756033346)\n",
      "No Information Rate: ToDo\n",
      "P-Value [Acc > NIR]: 1.0\n",
      "Kappa: -0.00509640514033\n",
      "Mcnemar's Test P-Value: ToDo\n",
      "\n",
      "\n",
      "Class Statistics:\n",
      "\n",
      "Classes                                         0           1\n",
      "Population                                   1144        1144\n",
      "P: Condition positive                         595         549\n",
      "N: Condition negative                         549         595\n",
      "Test outcome positive                        1139           5\n",
      "Test outcome negative                           5        1139\n",
      "TP: True Positive                             591           1\n",
      "TN: True Negative                               1         591\n",
      "FP: False Positive                            548           4\n",
      "FN: False Negative                              4         548\n",
      "TPR: (Sensitivity, hit rate, recall)     0.993277  0.00182149\n",
      "TNR=SPC: (Specificity)                 0.00182149    0.993277\n",
      "PPV: Pos Pred Value (Precision)          0.518876         0.2\n",
      "NPV: Neg Pred Value                           0.2    0.518876\n",
      "FPR: False-out                           0.998179  0.00672269\n",
      "FDR: False Discovery Rate                0.481124         0.8\n",
      "FNR: Miss Rate                         0.00672269    0.998179\n",
      "ACC: Accuracy                            0.517483    0.517483\n",
      "F1 score                                 0.681661  0.00361011\n",
      "MCC: Matthews correlation coefficient  -0.0371193  -0.0371193\n",
      "Informedness                           -0.0049012  -0.0049012\n",
      "Markedness                              -0.281124   -0.281124\n",
      "Prevalence                               0.520105    0.479895\n",
      "LR+: Positive likelihood ratio            0.99509    0.270947\n",
      "LR-: Negative likelihood ratio            3.69076     1.00493\n",
      "DOR: Diagnostic odds ratio               0.269617    0.269617\n",
      "FOR: False omission rate                      0.8    0.481124\n",
      "\n",
      " NEXT ttMNB \n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "Predicted   0.0  1.0  __all__\n",
      "Actual                       \n",
      "0.0         595    0      595\n",
      "1.0         548    1      549\n",
      "__all__    1143    1     1144\n",
      "\n",
      "\n",
      "Overall Statistics:\n",
      "\n",
      "Accuracy: 0.520979020979\n",
      "95% CI: (0.49157131720494407, 0.55027859874743323)\n",
      "No Information Rate: ToDo\n",
      "P-Value [Acc > NIR]: 1.0\n",
      "Kappa: 0.00189459673747\n",
      "Mcnemar's Test P-Value: ToDo\n",
      "\n",
      "\n",
      "Class Statistics:\n",
      "\n",
      "Classes                                         0           1\n",
      "Population                                   1144        1144\n",
      "P: Condition positive                         595         549\n",
      "N: Condition negative                         549         595\n",
      "Test outcome positive                        1143           1\n",
      "Test outcome negative                           1        1143\n",
      "TP: True Positive                             595           1\n",
      "TN: True Negative                               1         595\n",
      "FP: False Positive                            548           0\n",
      "FN: False Negative                              0         548\n",
      "TPR: (Sensitivity, hit rate, recall)            1  0.00182149\n",
      "TNR=SPC: (Specificity)                 0.00182149           1\n",
      "PPV: Pos Pred Value (Precision)           0.52056           1\n",
      "NPV: Neg Pred Value                             1     0.52056\n",
      "FPR: False-out                           0.998179           0\n",
      "FDR: False Discovery Rate                 0.47944           0\n",
      "FNR: Miss Rate                                  0    0.998179\n",
      "ACC: Accuracy                            0.520979    0.520979\n",
      "F1 score                                 0.684695  0.00363636\n",
      "MCC: Matthews correlation coefficient   0.0307928   0.0307928\n",
      "Informedness                           0.00182149  0.00182149\n",
      "Markedness                                0.52056     0.52056\n",
      "Prevalence                               0.520105    0.479895\n",
      "LR+: Positive likelihood ratio            1.00182         inf\n",
      "LR-: Negative likelihood ratio                  0    0.998179\n",
      "DOR: Diagnostic odds ratio                    inf         inf\n",
      "FOR: False omission rate                        0     0.47944\n",
      "\n",
      " NEXT ttBNB \n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "Predicted   0.0  1.0  __all__\n",
      "Actual                       \n",
      "0.0         593    2      595\n",
      "1.0         546    3      549\n",
      "__all__    1139    5     1144\n",
      "\n",
      "\n",
      "Overall Statistics:\n",
      "\n",
      "Accuracy: 0.520979020979\n",
      "95% CI: (0.49157131720494407, 0.55027859874743323)\n",
      "No Information Rate: ToDo\n",
      "P-Value [Acc > NIR]: 1.0\n",
      "Kappa: 0.00218690214329\n",
      "Mcnemar's Test P-Value: ToDo\n",
      "\n",
      "\n",
      "Class Statistics:\n",
      "\n",
      "Classes                                         0           1\n",
      "Population                                   1144        1144\n",
      "P: Condition positive                         595         549\n",
      "N: Condition negative                         549         595\n",
      "Test outcome positive                        1139           5\n",
      "Test outcome negative                           5        1139\n",
      "TP: True Positive                             593           3\n",
      "TN: True Negative                               3         593\n",
      "FP: False Positive                            546           2\n",
      "FN: False Negative                              2         546\n",
      "TPR: (Sensitivity, hit rate, recall)     0.996639  0.00546448\n",
      "TNR=SPC: (Specificity)                 0.00546448    0.996639\n",
      "PPV: Pos Pred Value (Precision)          0.520632         0.6\n",
      "NPV: Neg Pred Value                           0.6    0.520632\n",
      "FPR: False-out                           0.994536  0.00336134\n",
      "FDR: False Discovery Rate                0.479368         0.4\n",
      "FNR: Miss Rate                         0.00336134    0.994536\n",
      "ACC: Accuracy                            0.520979    0.520979\n",
      "F1 score                                 0.683968   0.0108303\n",
      "MCC: Matthews correlation coefficient   0.0159281   0.0159281\n",
      "Informedness                           0.00210314  0.00210314\n",
      "Markedness                               0.120632    0.120632\n",
      "Prevalence                               0.520105    0.479895\n",
      "LR+: Positive likelihood ratio            1.00211     1.62568\n",
      "LR-: Negative likelihood ratio           0.615126     0.99789\n",
      "DOR: Diagnostic odds ratio                1.62912     1.62912\n",
      "FOR: False omission rate                      0.4    0.479368**OUTPUT MUTED**"
     ]
    }
   ],
   "source": [
    "for name, clf in zip(names, classifiers):\n",
    "    clf.fit(train_feat_neu[[\"StringLength\", \n",
    "                  \"Number_of_Words\", \"Number_of_Dots\", \"Number_of_Commas\", \"Number_of_Semicolons\", \n",
    "                  \"Number_of_Colons\", \"Average_Word_Length\", \"Lexical_Diversity\"]], train_class_neu)\n",
    "    y_pred = clf.predict(test_feat_neu[[\"StringLength\", \n",
    "                  \"Number_of_Words\", \"Number_of_Dots\", \"Number_of_Commas\", \"Number_of_Semicolons\", \n",
    "                  \"Number_of_Colons\", \"Average_Word_Length\", \"Lexical_Diversity\"]])\n",
    "    \n",
    "    cm = ConfusionMatrix(test_class_neu, y_pred)\n",
    "    cm.print_stats()\n",
    "    print(\"\\n NEXT\", name, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.618 (+/- 0.02) [SVC]\n",
      "[ 0.62298387  0.60987903  0.61794355  0.60987903  0.61995968  0.62096774\n",
      "  0.60987903  0.63874874  0.63067608  0.60040363]\n",
      "Accuracy: 0.576 (+/- 0.20) [LSVC]\n",
      "[ 0.61995968  0.60887097  0.38810484  0.61189516  0.625       0.63709677\n",
      "  0.62298387  0.629667    0.64682139  0.37134208]\n"
     ]
    }
   ],
   "source": [
    "eclf = VotingClassifier(estimators=[\n",
    "        (\"svc\", ttSVC),\n",
    "        (\"linear_svc\", ttLinearSVC)], voting='hard')\n",
    "\n",
    "\n",
    "for clf, label in zip([ttSVC, ttLinearSVC], [\"SVC\", \"LSVC\"]):\n",
    "    scores = cross_validation.cross_val_score(clf, neu_X[[\"StringLength\", \n",
    "                  \"Number_of_Words\", \"Number_of_Dots\", \"Number_of_Commas\", \"Number_of_Semicolons\", \n",
    "                  \"Number_of_Colons\", \"Average_Word_Length\", \"Lexical_Diversity\"]], neu_Y, cv=skf, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.3f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std()*2, label))\n",
    "    print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn.cross_validation.StratifiedKFold(labels=[1 1 1 ..., 1 1 1], n_folds=10, shuffle=True, random_state=5152)\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(neu[\"cNEU\"], n_folds=10, shuffle=True, random_state = 5152)\n",
    "print(skf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(neu[\"cNEU\"], n_folds=10, shuffle=TRUE, random_state = 5152)\n",
    "print(skf)  \n",
    "\n",
    "for train_index, test_index in skf:\n",
    "#     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "#     X_train, X_test = X[train_index], X[test_index]\n",
    "#     y_train, y_test = y[train_index], y[test_index]\n",
    "    train_feat_neu \n",
    "    test_feat_neu\n",
    "    train_class_neu\n",
    "    gt = test_class_neu\n",
    "    \n",
    "    print(metrics.classification_report(personality_trait_comb, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predicted = mku.predict(test_neu[[\"StringLength\", \n",
    "#                   \"Number_of_Words\", \"Number_of_Dots\", \"Number_of_Commas\", \"Number_of_Semicolons\", \n",
    "#                   \"Number_of_Colons\", \"Average_Word_Length\", \"Lexical_Diversity\"]])"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
