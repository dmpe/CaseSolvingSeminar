{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cython extension is already loaded. To reload it, use:\n",
      "  %reload_ext cython\n",
      "The cythonmagic extension is already loaded. To reload it, use:\n",
      "  %reload_ext cythonmagic\n"
     ]
    }
   ],
   "source": [
    "%load_ext cython\n",
    "%load_ext cythonmagic\n",
    "%matplotlib inline\n",
    "%matplotlib notebook\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, reprlib, sys\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import *\n",
    "import random as ran\n",
    "from logging import *\n",
    "from pprint import *\n",
    "from time import *\n",
    "import shlex, subprocess\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "\n",
    "from scipy.cluster.vq import *\n",
    "\n",
    "import nltk as n\n",
    "import nltk, nltk.classify.util, nltk.metrics, nltk.tokenize, nltk.stem\n",
    "from nltk.corpus import *\n",
    "from nltk.stem import *\n",
    "from nltk.classify import *\n",
    "from nltk.collocations import *\n",
    "from nltk.metrics import *\n",
    "from nltk.probability import *\n",
    "from nltk.classify.scikitlearn import *\n",
    "from nltk.tag.sequential import *\n",
    "from nltk.tag import *\n",
    "from nltk.tag.util import *\n",
    "# n.download()\n",
    "\n",
    "from sklearn_pandas import *\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn import *\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.svm import *\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.cross_validation import *\n",
    "from sklearn.pipeline import *\n",
    "from sklearn.multiclass import *\n",
    "from sklearn.datasets import *\n",
    "from sklearn.naive_bayes import *\n",
    "from sklearn.neighbors import *\n",
    "from sklearn.feature_selection import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.tree import *\n",
    "from sklearn.grid_search import *\n",
    "from sklearn.base import *\n",
    "from sklearn.datasets.twenty_newsgroups import *\n",
    "from sklearn.decomposition import *\n",
    "from sklearn.feature_extraction import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.utils import *\n",
    "\n",
    "sk.utils.check_random_state(5125)\n",
    "ran.seed(5125)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R script adding new features to dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# http://www.mango-solutions.com/wp/2015/10/integrating-python-and-r-part-ii-executing-r-from-python-and-vice-versa/\n",
    "command = 'Rscript'\n",
    "path2script = 'insert_features.R'\n",
    "\n",
    "# Build subprocess command\n",
    "cmd = [command, path2script]\n",
    "\n",
    "subprocess.check_output(cmd, universal_newlines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>#AUTHID</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>sEXT</th>\n",
       "      <th>sNEU</th>\n",
       "      <th>sAGR</th>\n",
       "      <th>sCON</th>\n",
       "      <th>sOPN</th>\n",
       "      <th>cEXT</th>\n",
       "      <th>cNEU</th>\n",
       "      <th>...</th>\n",
       "      <th>Number_of_Dots</th>\n",
       "      <th>Number_of_Commas</th>\n",
       "      <th>Number_of_Semicolons</th>\n",
       "      <th>Number_of_Colons</th>\n",
       "      <th>Average_Word_Length</th>\n",
       "      <th>Lexical_Diversity</th>\n",
       "      <th>Number_of_FunctionalWords</th>\n",
       "      <th>Number_of_Pronouns</th>\n",
       "      <th>Number_of_PROPNAMEs</th>\n",
       "      <th>SentimentNumeric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
       "      <td>likes the sound of thunder.</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.4</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.400</td>\n",
       "      <td>0.700</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
       "      <td>is so sleepy it's not even funny that's she ca...</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.4</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.615</td>\n",
       "      <td>0.577</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
       "      <td>is sore and wants the knot of muscles at the b...</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.4</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.500</td>\n",
       "      <td>0.509</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
       "      <td>likes how the day sounds in this new song.</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.4</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.667</td>\n",
       "      <td>0.611</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
       "      <td>is home. &lt;3</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.4</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.333</td>\n",
       "      <td>0.857</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                           #AUTHID  \\\n",
       "0           1  b7b7764cfa1c523e4e93ab2a79a946c4   \n",
       "1           2  b7b7764cfa1c523e4e93ab2a79a946c4   \n",
       "2           3  b7b7764cfa1c523e4e93ab2a79a946c4   \n",
       "3           4  b7b7764cfa1c523e4e93ab2a79a946c4   \n",
       "4           5  b7b7764cfa1c523e4e93ab2a79a946c4   \n",
       "\n",
       "                                              STATUS  sEXT  sNEU  sAGR  sCON  \\\n",
       "0                        likes the sound of thunder.  2.65     3  3.15  3.25   \n",
       "1  is so sleepy it's not even funny that's she ca...  2.65     3  3.15  3.25   \n",
       "2  is sore and wants the knot of muscles at the b...  2.65     3  3.15  3.25   \n",
       "3         likes how the day sounds in this new song.  2.65     3  3.15  3.25   \n",
       "4                                        is home. <3  2.65     3  3.15  3.25   \n",
       "\n",
       "   sOPN cEXT cNEU        ...        Number_of_Dots Number_of_Commas  \\\n",
       "0   4.4    n    y        ...                     1                0   \n",
       "1   4.4    n    y        ...                     1                0   \n",
       "2   4.4    n    y        ...                     1                1   \n",
       "3   4.4    n    y        ...                     1                0   \n",
       "4   4.4    n    y        ...                     1                0   \n",
       "\n",
       "  Number_of_Semicolons Number_of_Colons  Average_Word_Length  \\\n",
       "0                    0                0                4.400   \n",
       "1                    0                0                3.615   \n",
       "2                    0                0                3.500   \n",
       "3                    0                0                3.667   \n",
       "4                    0                0                2.333   \n",
       "\n",
       "   Lexical_Diversity  Number_of_FunctionalWords  Number_of_Pronouns  \\\n",
       "0              0.700                          2                   0   \n",
       "1              0.577                         10                   1   \n",
       "2              0.509                         14                   1   \n",
       "3              0.611                          4                   0   \n",
       "4              0.857                          1                   0   \n",
       "\n",
       "   Number_of_PROPNAMEs  SentimentNumeric  \n",
       "0                    0                 2  \n",
       "1                    0                 0  \n",
       "2                    0                 1  \n",
       "3                    0                 2  \n",
       "4                    0                 2  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_n = pd.read_csv(\"../raw_data/data_n.csv\", parse_dates=True, infer_datetime_format=True)\n",
    "data_n.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace 'y' and 'n'   AND easy split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>#AUTHID</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>sEXT</th>\n",
       "      <th>sNEU</th>\n",
       "      <th>sAGR</th>\n",
       "      <th>sCON</th>\n",
       "      <th>sOPN</th>\n",
       "      <th>cEXT</th>\n",
       "      <th>cNEU</th>\n",
       "      <th>...</th>\n",
       "      <th>Number_of_Dots</th>\n",
       "      <th>Number_of_Commas</th>\n",
       "      <th>Number_of_Semicolons</th>\n",
       "      <th>Number_of_Colons</th>\n",
       "      <th>Average_Word_Length</th>\n",
       "      <th>Lexical_Diversity</th>\n",
       "      <th>Number_of_FunctionalWords</th>\n",
       "      <th>Number_of_Pronouns</th>\n",
       "      <th>Number_of_PROPNAMEs</th>\n",
       "      <th>SentimentNumeric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
       "      <td>likes the sound of thunder.</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                           #AUTHID                       STATUS  \\\n",
       "0           1  b7b7764cfa1c523e4e93ab2a79a946c4  likes the sound of thunder.   \n",
       "\n",
       "   sEXT  sNEU  sAGR  sCON  sOPN  cEXT  cNEU        ...         Number_of_Dots  \\\n",
       "0  2.65     3  3.15  3.25   4.4     0     1        ...                      1   \n",
       "\n",
       "   Number_of_Commas  Number_of_Semicolons Number_of_Colons  \\\n",
       "0                 0                     0                0   \n",
       "\n",
       "   Average_Word_Length  Lexical_Diversity  Number_of_FunctionalWords  \\\n",
       "0                  4.4                0.7                          2   \n",
       "\n",
       "   Number_of_Pronouns  Number_of_PROPNAMEs  SentimentNumeric  \n",
       "0                   0                    0                 2  \n",
       "\n",
       "[1 rows x 33 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# http://stackoverflow.com/a/17702781\n",
    "d = {'n': 0, 'y': 1}\n",
    "data_n = data_n.replace(d)\n",
    "data_n.head(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#norm:http://blog.yhat.com/posts/predicting-customer-churn-with-sklearn.html\n",
    "# scaler = StandardScaler()\n",
    "# X = scaler.fit_transform(X)\n",
    "# to_drop = ['State','Area Code','Phone','Churn?']\n",
    "# churn_feat_space = data_n.drop(to_drop,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neu = data_n[[\"#AUTHID\",\"STATUS\",\"cNEU\",\"StringLength\", \n",
    "                  \"Number_of_Words\", \"Number_of_Dots\", \"Number_of_Commas\", \"Number_of_Semicolons\", \n",
    "                  \"Number_of_Colons\", \"Average_Word_Length\", \"Lexical_Diversity\", \"Number_of_FunctionalWords\", \"Number_of_Pronouns\", \"Number_of_PROPNAMEs\", \"SentimentNumeric\"]]\n",
    "ext = data_n[[\"#AUTHID\",\"STATUS\",\"cEXT\", \"StringLength\", \n",
    "                  \"Number_of_Words\", \"Number_of_Dots\", \"Number_of_Commas\", \"Number_of_Semicolons\", \n",
    "                  \"Number_of_Colons\", \"Average_Word_Length\", \"Lexical_Diversity\", \"Number_of_FunctionalWords\", \"Number_of_Pronouns\", \"Number_of_PROPNAMEs\", \"SentimentNumeric\"]]\n",
    "agr = data_n[[\"#AUTHID\",\"STATUS\",\"cAGR\",\"StringLength\", \n",
    "                  \"Number_of_Words\", \"Number_of_Dots\", \"Number_of_Commas\", \"Number_of_Semicolons\", \n",
    "                  \"Number_of_Colons\", \"Average_Word_Length\", \"Lexical_Diversity\", \"Number_of_FunctionalWords\", \"Number_of_Pronouns\", \"Number_of_PROPNAMEs\", \"SentimentNumeric\"]]\n",
    "con = data_n[[\"#AUTHID\",\"STATUS\",\"cCON\",\"StringLength\", \n",
    "                  \"Number_of_Words\", \"Number_of_Dots\", \"Number_of_Commas\", \"Number_of_Semicolons\", \n",
    "                  \"Number_of_Colons\", \"Average_Word_Length\", \"Lexical_Diversity\", \"Number_of_FunctionalWords\", \"Number_of_Pronouns\", \"Number_of_PROPNAMEs\", \"SentimentNumeric\"]]\n",
    "opn = data_n[[\"#AUTHID\",\"STATUS\",\"cOPN\", \"StringLength\", \n",
    "                  \"Number_of_Words\", \"Number_of_Dots\", \"Number_of_Commas\", \"Number_of_Semicolons\", \n",
    "                  \"Number_of_Colons\", \"Average_Word_Length\", \"Lexical_Diversity\", \"Number_of_FunctionalWords\", \"Number_of_Pronouns\", \"Number_of_PROPNAMEs\", \"SentimentNumeric\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split stra. k-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# neu = data_n[[\"#AUTHID\",\"STATUS\",\"cNEU\"]]\n",
    "# train_neu, test_neu, y_train, y_test = sk.cross_validation.train_test_split(neu, neu[\"cNEU\"], train_size = 0.66, stratify= neu[\"cNEU\"])\n",
    "# train_neu, test_neu, y_train, y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6545, 15) (3372, 15) (6545,) (3372,)\n"
     ]
    }
   ],
   "source": [
    "train_feat_neu, test_feat_neu, train_class_neu, test_class_neu = sk.cross_validation.train_test_split(neu, neu[\"cNEU\"], train_size = 0.66, stratify = neu[\"cNEU\"],random_state= 5152)\n",
    "print(train_feat_neu.shape, test_feat_neu.shape,train_class_neu.shape ,test_class_neu.shape)\n",
    "\n",
    "neu_X = train_feat_neu.append(test_feat_neu)\n",
    "neu_Y = train_class_neu.append(test_class_neu)\n",
    "\n",
    "train_feat_ext, test_feat_ext, train_class_ext, test_class_ext = sk.cross_validation.train_test_split(ext, ext[\"cEXT\"], train_size = 0.66, stratify = ext[\"cEXT\"],random_state= 5152)\n",
    "\n",
    "ext_X = train_feat_ext.append(test_feat_ext)\n",
    "ext_Y = train_class_ext.append(test_class_ext)\n",
    "\n",
    "train_feat_agr, test_feat_agr, train_class_agr, test_class_agr = sk.cross_validation.train_test_split(agr, agr[\"cAGR\"], train_size = 0.66, stratify = agr[\"cAGR\"],random_state= 5152)\n",
    "train_feat_con, test_feat_con, train_class_con, test_class_con = sk.cross_validation.train_test_split(con, con[\"cCON\"], train_size = 0.66, stratify = con[\"cCON\"],random_state= 5152)\n",
    "train_feat_opn, test_feat_opn, train_class_opn, test_class_opn = sk.cross_validation.train_test_split(opn, opn[\"cOPN\"], train_size = 0.66, stratify = opn[\"cOPN\"],random_state= 5152)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mku = sk.pipeline.make_pipeline(SGDClassifier(), LinearSVC(),\n",
    "#                                # BernoulliNB(), #MultinomialNB()\n",
    "#                                # KNeighborsClassifier(),\n",
    "#               RandomForestClassifier(n_jobs=-1),AdaBoostClassifier()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of classifiers \n",
    "with their configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nick_names = [\"tt SVC\", \"tt Linear SVC\", \"tt MultinomiaNB\", \"tt BernoulliNB\", \"ttRF\", \"ttAD\", \"ttKNN\"]\n",
    "classifiers = [\n",
    "    SVC(cache_size=500, kernel = \"rbf\", decision_function_shape = \"ovr\", random_state = 5152),\n",
    "    LinearSVC(random_state = 5152),\n",
    "    MultinomialNB(),\n",
    "    BernoulliNB(),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1, n_jobs=-1, random_state = 5152),\n",
    "    AdaBoostClassifier(random_state = 5152),\n",
    "    KNeighborsClassifier()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train + Test NEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FOR: tt SVC\n",
      "Accuracy score:  0.608540925267\n",
      "MAR:  0.391459074733\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.94      0.75      2108\n",
      "          1       0.35      0.05      0.09      1264\n",
      "\n",
      "avg / total       0.52      0.61      0.50      3372\n",
      "\n",
      "\n",
      "FOR: tt Linear SVC\n",
      "Accuracy score:  0.379003558719\n",
      "MAR:  0.620996441281\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.03      0.05      2108\n",
      "          1       0.37      0.97      0.54      1264\n",
      "\n",
      "avg / total       0.50      0.38      0.23      3372\n",
      "\n",
      "\n",
      "FOR: tt MultinomiaNB\n",
      "Accuracy score:  0.624851720047\n",
      "MAR:  0.375148279953\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.99      0.77      2108\n",
      "          1       0.48      0.01      0.02      1264\n",
      "\n",
      "avg / total       0.57      0.62      0.49      3372\n",
      "\n",
      "\n",
      "FOR: tt BernoulliNB\n",
      "Accuracy score:  0.624555160142\n",
      "MAR:  0.375444839858\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      1.00      0.77      2108\n",
      "          1       0.40      0.00      0.01      1264\n",
      "\n",
      "avg / total       0.54      0.62      0.48      3372\n",
      "\n",
      "\n",
      "FOR: ttRF\n",
      "Accuracy score:  0.625444839858\n",
      "MAR:  0.374555160142\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      1.00      0.77      2108\n",
      "          1       0.53      0.01      0.01      1264\n",
      "\n",
      "avg / total       0.59      0.63      0.49      3372\n",
      "\n",
      "\n",
      "FOR: ttAD\n",
      "Accuracy score:  0.620699881376\n",
      "MAR:  0.379300118624\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.98      0.76      2108\n",
      "          1       0.41      0.03      0.05      1264\n",
      "\n",
      "avg / total       0.55      0.62      0.50      3372\n",
      "\n",
      "\n",
      "FOR: ttKNN\n",
      "Accuracy score:  0.551601423488\n",
      "MAR:  0.448398576512\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.73      0.67      2108\n",
      "          1       0.36      0.25      0.30      1264\n",
      "\n",
      "avg / total       0.52      0.55      0.53      3372\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print(classifiers, nick_names)\n",
    "for name, clf in zip(nick_names, classifiers):\n",
    "    clf.fit(train_feat_neu[[\"StringLength\", \n",
    "                  \"Number_of_Words\", \"Number_of_Dots\", \"Number_of_Commas\", \"Number_of_Semicolons\", \n",
    "                  \"Number_of_Colons\", \"Average_Word_Length\", \"Lexical_Diversity\", \"Number_of_FunctionalWords\", \"Number_of_Pronouns\", \"Number_of_PROPNAMEs\", \"SentimentNumeric\"]], train_class_neu)\n",
    "    y_pred_neu = clf.predict(test_feat_neu[[\"StringLength\", \n",
    "                  \"Number_of_Words\", \"Number_of_Dots\", \"Number_of_Commas\", \"Number_of_Semicolons\", \n",
    "                  \"Number_of_Colons\", \"Average_Word_Length\", \"Lexical_Diversity\", \"Number_of_FunctionalWords\", \"Number_of_Pronouns\", \"Number_of_PROPNAMEs\", \"SentimentNumeric\"]])\n",
    "    print(\"\\nFOR:\", name)\n",
    "    print(\"Accuracy score: \", sk.metrics.accuracy_score(test_class_neu, y_pred_neu))\n",
    "    print(sk.metrics.classification_report(test_class_neu, y_pred_neu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ttSVC' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-105-15f83439b000>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m eclf = VotingClassifier(estimators=[\n\u001b[1;32m----> 2\u001b[1;33m         \u001b[1;33m(\u001b[0m\u001b[1;34m\"svc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mttSVC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m         (\"linear_svc\", ttLinearSVC)], voting='hard')\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ttSVC' is not defined"
     ]
    }
   ],
   "source": [
    "eclf = VotingClassifier(estimators=[\n",
    "        (\"svc\", ttSVC),\n",
    "        (\"linear_svc\", ttLinearSVC)], voting='hard')\n",
    "\n",
    "\n",
    "for clf, label in zip([ttSVC, ttLinearSVC], [\"SVC\", \"LSVC\"]):\n",
    "    scores = cross_validation.cross_val_score(clf, neu_X[[\"StringLength\", \n",
    "                  \"Number_of_Words\", \"Number_of_Dots\", \"Number_of_Commas\", \"Number_of_Semicolons\", \n",
    "                  \"Number_of_Colons\", \"Average_Word_Length\", \"Lexical_Diversity\"]], neu_Y, cv=skf, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.3f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std()*2, label))\n",
    "    print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train + Test EXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn.cross_validation.StratifiedKFold(labels=[0 0 0 ..., 1 0 1], n_folds=10, shuffle=True, random_state=5152)\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(ext[\"cEXT\"], n_folds=10, shuffle=True, random_state = 5152)\n",
    "print(skf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FOR: tt SVC\n",
      "Accuracy score:  0.567615658363\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.86      0.70      1941\n",
      "          1       0.47      0.17      0.25      1431\n",
      "\n",
      "avg / total       0.54      0.57      0.51      3372\n",
      "\n",
      "[[1673  268]\n",
      " [1190  241]]\n",
      "0.248453608247\n",
      "0.47347740668\n",
      "0.168413696716\n",
      "Accuracy: 0.567 (+/- 0.03) [tt SVC]\n",
      "\n",
      "FOR: tt Linear SVC\n",
      "Accuracy score:  0.575622775801\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      1.00      0.73      1941\n",
      "          1       0.00      0.00      0.00      1431\n",
      "\n",
      "avg / total       0.33      0.58      0.42      3372\n",
      "\n",
      "[[1941    0]\n",
      " [1431    0]]\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Accuracy: 0.497 (+/- 0.13) [tt Linear SVC]\n",
      "\n",
      "FOR: tt MultinomiaNB\n",
      "Accuracy score:  0.580367734282\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.98      0.73      1941\n",
      "          1       0.58      0.04      0.08      1431\n",
      "\n",
      "avg / total       0.58      0.58      0.45      3372\n",
      "\n",
      "[[1898   43]\n",
      " [1372   59]]\n",
      "0.0769732550554\n",
      "0.578431372549\n",
      "0.0412299091544\n",
      "Accuracy: 0.578 (+/- 0.03) [tt MultinomiaNB]\n",
      "\n",
      "FOR: tt BernoulliNB\n",
      "Accuracy score:  0.586002372479\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.93      0.72      1941\n",
      "          1       0.56      0.12      0.20      1431\n",
      "\n",
      "avg / total       0.58      0.59      0.50      3372\n",
      "\n",
      "[[1802  139]\n",
      " [1257  174]]\n",
      "0.199541284404\n",
      "0.555910543131\n",
      "0.121593291405\n",
      "Accuracy: 0.580 (+/- 0.03) [tt BernoulliNB]\n",
      "\n",
      "FOR: ttRF\n",
      "Accuracy score:  0.587485172005\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.99      0.73      1941\n",
      "          1       0.70      0.05      0.09      1431\n",
      "\n",
      "avg / total       0.63      0.59      0.46      3372\n",
      "\n",
      "[[1912   29]\n",
      " [1362   69]]\n",
      "0.0902550686723\n",
      "0.704081632653\n",
      "0.0482180293501\n",
      "Accuracy: 0.579 (+/- 0.03) [ttRF]\n",
      "\n",
      "FOR: ttAD\n",
      "Accuracy score:  0.586298932384\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.91      0.72      1941\n",
      "          1       0.55      0.15      0.23      1431\n",
      "\n",
      "avg / total       0.57      0.59      0.51      3372\n",
      "\n",
      "[[1763  178]\n",
      " [1217  214]]\n",
      "0.234777838727\n",
      "0.545918367347\n",
      "0.149545772187\n",
      "Accuracy: 0.579 (+/- 0.03) [ttAD]\n",
      "\n",
      "FOR: ttKNN\n",
      "Accuracy score:  0.534697508897\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.65      0.62      1941\n",
      "          1       0.44      0.38      0.41      1431\n",
      "\n",
      "avg / total       0.53      0.53      0.53      3372\n",
      "\n",
      "[[1254  687]\n",
      " [ 882  549]]\n",
      "0.411698537683\n",
      "0.444174757282\n",
      "0.383647798742\n",
      "Accuracy: 0.527 (+/- 0.02) [ttKNN]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# print(classifiers, nick_names)\n",
    "for name, clf in zip(nick_names, classifiers):\n",
    "    clf.fit(train_feat_ext[[\"StringLength\", \n",
    "                  \"Number_of_Words\", \"Number_of_Dots\", \"Number_of_Commas\", \"Number_of_Semicolons\", \n",
    "                  \"Number_of_Colons\", \"Average_Word_Length\", \"Lexical_Diversity\", \"Number_of_FunctionalWords\", \"Number_of_Pronouns\", \"Number_of_PROPNAMEs\", \"SentimentNumeric\"]], train_class_ext)\n",
    "    y_pred_ext = clf.predict(test_feat_ext[[\"StringLength\", \n",
    "                  \"Number_of_Words\", \"Number_of_Dots\", \"Number_of_Commas\", \"Number_of_Semicolons\", \n",
    "                  \"Number_of_Colons\", \"Average_Word_Length\", \"Lexical_Diversity\", \"Number_of_FunctionalWords\", \"Number_of_Pronouns\", \"Number_of_PROPNAMEs\", \"SentimentNumeric\"]])\n",
    "    print(\"\\nFOR:\", name)\n",
    "    print(\"Accuracy score: \", sk.metrics.accuracy_score(test_class_ext, y_pred_ext))\n",
    "    print(sk.metrics.classification_report(test_class_ext, y_pred_ext))\n",
    "    print(sk.metrics.confusion_matrix(test_class_ext, y_pred_ext))\n",
    "    print(sk.metrics.f1_score(test_class_ext, y_pred_ext))\n",
    "    print(sk.metrics.precision_score(test_class_ext, y_pred_ext))\n",
    "    print(sk.metrics.recall_score(test_class_ext, y_pred_ext))\n",
    "    \n",
    "    scores = sk.cross_validation.cross_val_score(clf, ext_X[[\"StringLength\", \n",
    "                  \"Number_of_Words\", \"Number_of_Dots\", \"Number_of_Commas\", \"Number_of_Semicolons\", \n",
    "                  \"Number_of_Colons\", \"Average_Word_Length\", \"Lexical_Diversity\", \"Number_of_FunctionalWords\", \"Number_of_Pronouns\", \"Number_of_PROPNAMEs\", \"SentimentNumeric\"]], ext_Y, cv=skf, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.3f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std()*2, name))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train + Test CON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FOR: tt SVC\n",
      "Accuracy score:  0.534697508897\n",
      "MAR:  0.465302491103\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.71      0.62      1823\n",
      "          1       0.49      0.32      0.39      1549\n",
      "\n",
      "avg / total       0.52      0.53      0.52      3372\n",
      "\n",
      "\n",
      "FOR: tt Linear SVC\n",
      "Accuracy score:  0.459964412811\n",
      "MAR:  0.540035587189\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.00      0.01      1823\n",
      "          1       0.46      1.00      0.63      1549\n",
      "\n",
      "avg / total       0.52      0.46      0.29      3372\n",
      "\n",
      "\n",
      "FOR: tt MultinomiaNB\n",
      "Accuracy score:  0.535290628707\n",
      "MAR:  0.464709371293\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.81      0.65      1823\n",
      "          1       0.49      0.21      0.30      1549\n",
      "\n",
      "avg / total       0.52      0.54      0.49      3372\n",
      "\n",
      "\n",
      "FOR: tt BernoulliNB\n",
      "Accuracy score:  0.542408066429\n",
      "MAR:  0.457591933571\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.77      0.65      1823\n",
      "          1       0.50      0.27      0.35      1549\n",
      "\n",
      "avg / total       0.53      0.54      0.51      3372\n",
      "\n",
      "\n",
      "FOR: ttRF\n",
      "Accuracy score:  0.536180308422\n",
      "MAR:  0.463819691578\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.94      0.69      1823\n",
      "          1       0.46      0.06      0.10      1549\n",
      "\n",
      "avg / total       0.50      0.54      0.42      3372\n",
      "\n",
      "\n",
      "FOR: ttAD\n",
      "Accuracy score:  0.54359430605\n",
      "MAR:  0.45640569395\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.82      0.66      1823\n",
      "          1       0.51      0.22      0.31      1549\n",
      "\n",
      "avg / total       0.53      0.54      0.50      3372\n",
      "\n",
      "\n",
      "FOR: ttKNN\n",
      "Accuracy score:  0.535290628707\n",
      "MAR:  0.464709371293\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.61      0.59      1823\n",
      "          1       0.49      0.44      0.47      1549\n",
      "\n",
      "avg / total       0.53      0.54      0.53      3372\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print(classifiers, nick_names)\n",
    "for name, clf in zip(nick_names, classifiers):\n",
    "    clf.fit(train_feat_con[[\"StringLength\", \n",
    "                  \"Number_of_Words\", \"Number_of_Dots\", \"Number_of_Commas\", \"Number_of_Semicolons\", \n",
    "                  \"Number_of_Colons\", \"Average_Word_Length\", \"Lexical_Diversity\", \"Number_of_FunctionalWords\", \"Number_of_Pronouns\", \"Number_of_PROPNAMEs\", \"SentimentNumeric\"]], train_class_con)\n",
    "    y_pred_con = clf.predict(test_feat_con[[\"StringLength\", \n",
    "                  \"Number_of_Words\", \"Number_of_Dots\", \"Number_of_Commas\", \"Number_of_Semicolons\", \n",
    "                  \"Number_of_Colons\", \"Average_Word_Length\", \"Lexical_Diversity\", \"Number_of_FunctionalWords\", \"Number_of_Pronouns\", \"Number_of_PROPNAMEs\", \"SentimentNumeric\"]])\n",
    "    print(\"\\nFOR:\", name)\n",
    "    print(\"Accuracy score: \", sk.metrics.accuracy_score(test_class_con, y_pred_con))\n",
    "    print(sk.metrics.classification_report(test_class_con, y_pred_con))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train + Test AGR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FOR: tt SVC\n",
      "Accuracy score:  0.521352313167\n",
      "MAR:  0.478647686833\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.49      0.34      0.40      1581\n",
      "          1       0.54      0.68      0.60      1791\n",
      "\n",
      "avg / total       0.51      0.52      0.51      3372\n",
      "\n",
      "\n",
      "FOR: tt Linear SVC\n",
      "Accuracy score:  0.531731909846\n",
      "MAR:  0.468268090154\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.01      0.02      1581\n",
      "          1       0.53      0.99      0.69      1791\n",
      "\n",
      "avg / total       0.53      0.53      0.38      3372\n",
      "\n",
      "\n",
      "FOR: tt MultinomiaNB\n",
      "Accuracy score:  0.540925266904\n",
      "MAR:  0.459074733096\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.16      0.24      1581\n",
      "          1       0.54      0.88      0.67      1791\n",
      "\n",
      "avg / total       0.54      0.54      0.47      3372\n",
      "\n",
      "\n",
      "FOR: tt BernoulliNB\n",
      "Accuracy score:  0.548042704626\n",
      "MAR:  0.451957295374\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.18      0.27      1581\n",
      "          1       0.55      0.87      0.67      1791\n",
      "\n",
      "avg / total       0.55      0.55      0.48      3372\n",
      "\n",
      "\n",
      "FOR: ttRF\n",
      "Accuracy score:  0.545077105575\n",
      "MAR:  0.454922894425\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.16      0.25      1581\n",
      "          1       0.54      0.89      0.67      1791\n",
      "\n",
      "avg / total       0.55      0.55      0.47      3372\n",
      "\n",
      "\n",
      "FOR: ttAD\n",
      "Accuracy score:  0.546263345196\n",
      "MAR:  0.453736654804\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.34      0.41      1581\n",
      "          1       0.56      0.73      0.63      1791\n",
      "\n",
      "avg / total       0.54      0.55      0.53      3372\n",
      "\n",
      "\n",
      "FOR: ttKNN\n",
      "Accuracy score:  0.501779359431\n",
      "MAR:  0.498220640569\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.47      0.43      0.45      1581\n",
      "          1       0.53      0.56      0.55      1791\n",
      "\n",
      "avg / total       0.50      0.50      0.50      3372\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print(classifiers, nick_names)\n",
    "for name, clf in zip(nick_names, classifiers):\n",
    "    clf.fit(train_feat_agr[[\"StringLength\", \n",
    "                  \"Number_of_Words\", \"Number_of_Dots\", \"Number_of_Commas\", \"Number_of_Semicolons\", \n",
    "                  \"Number_of_Colons\", \"Average_Word_Length\", \"Lexical_Diversity\", \"Number_of_FunctionalWords\", \"Number_of_Pronouns\", \"Number_of_PROPNAMEs\", \"SentimentNumeric\"]], train_class_agr)\n",
    "    y_pred_agr = clf.predict(test_feat_agr[[\"StringLength\", \n",
    "                  \"Number_of_Words\", \"Number_of_Dots\", \"Number_of_Commas\", \"Number_of_Semicolons\", \n",
    "                  \"Number_of_Colons\", \"Average_Word_Length\", \"Lexical_Diversity\", \"Number_of_FunctionalWords\", \"Number_of_Pronouns\", \"Number_of_PROPNAMEs\", \"SentimentNumeric\"]])\n",
    "    print(\"\\nFOR:\", name)\n",
    "    print(\"Accuracy score: \", sk.metrics.accuracy_score(test_class_agr, y_pred_agr))\n",
    "    print(sk.metrics.classification_report(test_class_agr, y_pred_agr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train + Test OPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FOR: tt SVC\n",
      "Accuracy score:  0.742586002372\n",
      "MAR:  0.257413997628\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.42      0.01      0.01       866\n",
      "          1       0.74      1.00      0.85      2506\n",
      "\n",
      "avg / total       0.66      0.74      0.64      3372\n",
      "\n",
      "\n",
      "FOR: tt Linear SVC\n",
      "Accuracy score:  0.743179122183\n",
      "MAR:  0.256820877817\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       866\n",
      "          1       0.74      1.00      0.85      2506\n",
      "\n",
      "avg / total       0.55      0.74      0.63      3372\n",
      "\n",
      "\n",
      "FOR: tt MultinomiaNB\n",
      "Accuracy score:  0.744661921708\n",
      "MAR:  0.255338078292\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.02      0.03       866\n",
      "          1       0.75      1.00      0.85      2506\n",
      "\n",
      "avg / total       0.71      0.74      0.64      3372\n",
      "\n",
      "\n",
      "FOR: tt BernoulliNB\n",
      "Accuracy score:  0.743179122183\n",
      "MAR:  0.256820877817\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       866\n",
      "          1       0.74      1.00      0.85      2506\n",
      "\n",
      "avg / total       0.55      0.74      0.63      3372\n",
      "\n",
      "\n",
      "FOR: ttRF\n",
      "Accuracy score:  0.742586002372\n",
      "MAR:  0.257413997628\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.25      0.00      0.00       866\n",
      "          1       0.74      1.00      0.85      2506\n",
      "\n",
      "avg / total       0.62      0.74      0.63      3372\n",
      "\n",
      "\n",
      "FOR: ttAD\n",
      "Accuracy score:  0.741696322657\n",
      "MAR:  0.258303677343\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.41      0.01      0.02       866\n",
      "          1       0.74      0.99      0.85      2506\n",
      "\n",
      "avg / total       0.66      0.74      0.64      3372\n",
      "\n",
      "\n",
      "FOR: ttKNN\n",
      "Accuracy score:  0.69128113879\n",
      "MAR:  0.30871886121\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.28      0.13      0.18       866\n",
      "          1       0.75      0.89      0.81      2506\n",
      "\n",
      "avg / total       0.63      0.69      0.65      3372\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# print(classifiers, nick_names)\n",
    "for name, clf in zip(nick_names, classifiers):\n",
    "    clf.fit(train_feat_opn[[\"StringLength\", \n",
    "                  \"Number_of_Words\", \"Number_of_Dots\", \"Number_of_Commas\", \"Number_of_Semicolons\", \n",
    "                  \"Number_of_Colons\", \"Average_Word_Length\", \"Lexical_Diversity\", \"Number_of_FunctionalWords\", \"Number_of_Pronouns\", \"Number_of_PROPNAMEs\", \"SentimentNumeric\"]], train_class_opn)\n",
    "    y_pred_opn = clf.predict(test_feat_opn[[\"StringLength\", \n",
    "                  \"Number_of_Words\", \"Number_of_Dots\", \"Number_of_Commas\", \"Number_of_Semicolons\", \n",
    "                  \"Number_of_Colons\", \"Average_Word_Length\", \"Lexical_Diversity\", \"Number_of_FunctionalWords\", \"Number_of_Pronouns\", \"Number_of_PROPNAMEs\", \"SentimentNumeric\"]])\n",
    "    print(\"\\nFOR:\", name)\n",
    "    print(\"Accuracy score: \", sk.metrics.accuracy_score(test_class_opn, y_pred_opn))\n",
    "    print(sk.metrics.classification_report(test_class_opn, y_pred_opn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
