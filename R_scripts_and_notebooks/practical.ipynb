{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cython extension is already loaded. To reload it, use:\n",
      "  %reload_ext cython\n",
      "The cythonmagic extension is already loaded. To reload it, use:\n",
      "  %reload_ext cythonmagic\n"
     ]
    }
   ],
   "source": [
    "%load_ext cython\n",
    "%load_ext cythonmagic\n",
    "%matplotlib inline\n",
    "%matplotlib notebook\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, reprlib, sys\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import *\n",
    "import random as ran\n",
    "from logging import *\n",
    "from pprint import *\n",
    "from time import *\n",
    "import shlex, subprocess\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "\n",
    "from scipy.cluster.vq import *\n",
    "\n",
    "import nltk as n\n",
    "import nltk, nltk.classify.util, nltk.metrics, nltk.tokenize, nltk.stem\n",
    "from nltk.corpus import *\n",
    "from nltk.stem import *\n",
    "from nltk.classify import *\n",
    "from nltk.collocations import *\n",
    "from nltk.metrics import *\n",
    "from nltk.probability import *\n",
    "from nltk.classify.scikitlearn import *\n",
    "from nltk.tag.sequential import *\n",
    "from nltk.tag import *\n",
    "from nltk.tag.util import *\n",
    "# n.download()\n",
    "\n",
    "from sklearn_pandas import *\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn import *\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.svm import *\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.cross_validation import *\n",
    "from sklearn.pipeline import *\n",
    "from sklearn.multiclass import *\n",
    "from sklearn.datasets import *\n",
    "from sklearn.naive_bayes import *\n",
    "from sklearn.neighbors import *\n",
    "from sklearn.feature_selection import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.tree import *\n",
    "from sklearn.grid_search import *\n",
    "from sklearn.base import *\n",
    "from sklearn.datasets.twenty_newsgroups import *\n",
    "from sklearn.decomposition import *\n",
    "from sklearn.feature_extraction import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.utils import *\n",
    "\n",
    "sk.utils.check_random_state(5125)\n",
    "ran.seed(5125)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R script adding new features to dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# http://www.mango-solutions.com/wp/2015/10/integrating-python-and-r-part-ii-executing-r-from-python-and-vice-versa/\n",
    "command = 'Rscript'\n",
    "path2script = 'insert_features.R'\n",
    "\n",
    "# Build subprocess command\n",
    "cmd = [command, path2script]\n",
    "\n",
    "subprocess.check_output(cmd, universal_newlines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>#AUTHID</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>sEXT</th>\n",
       "      <th>sNEU</th>\n",
       "      <th>sAGR</th>\n",
       "      <th>sCON</th>\n",
       "      <th>sOPN</th>\n",
       "      <th>cEXT</th>\n",
       "      <th>cNEU</th>\n",
       "      <th>...</th>\n",
       "      <th>Number_of_Dots</th>\n",
       "      <th>Number_of_Commas</th>\n",
       "      <th>Number_of_Semicolons</th>\n",
       "      <th>Number_of_Colons</th>\n",
       "      <th>Average_Word_Length</th>\n",
       "      <th>Lexical_Diversity</th>\n",
       "      <th>Number_of_FunctionalWords</th>\n",
       "      <th>Number_of_Pronouns</th>\n",
       "      <th>Number_of_PROPNAMEs</th>\n",
       "      <th>SentimentNumeric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
       "      <td>likes the sound of thunder.</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.4</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.400</td>\n",
       "      <td>0.700</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
       "      <td>is so sleepy it's not even funny that's she ca...</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.4</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.615</td>\n",
       "      <td>0.577</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
       "      <td>is sore and wants the knot of muscles at the b...</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.4</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.500</td>\n",
       "      <td>0.509</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
       "      <td>likes how the day sounds in this new song.</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.4</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.667</td>\n",
       "      <td>0.611</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
       "      <td>is home. &lt;3</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.4</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.333</td>\n",
       "      <td>0.857</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                           #AUTHID  \\\n",
       "0           1  b7b7764cfa1c523e4e93ab2a79a946c4   \n",
       "1           2  b7b7764cfa1c523e4e93ab2a79a946c4   \n",
       "2           3  b7b7764cfa1c523e4e93ab2a79a946c4   \n",
       "3           4  b7b7764cfa1c523e4e93ab2a79a946c4   \n",
       "4           5  b7b7764cfa1c523e4e93ab2a79a946c4   \n",
       "\n",
       "                                              STATUS  sEXT  sNEU  sAGR  sCON  \\\n",
       "0                        likes the sound of thunder.  2.65     3  3.15  3.25   \n",
       "1  is so sleepy it's not even funny that's she ca...  2.65     3  3.15  3.25   \n",
       "2  is sore and wants the knot of muscles at the b...  2.65     3  3.15  3.25   \n",
       "3         likes how the day sounds in this new song.  2.65     3  3.15  3.25   \n",
       "4                                        is home. <3  2.65     3  3.15  3.25   \n",
       "\n",
       "   sOPN cEXT cNEU        ...        Number_of_Dots Number_of_Commas  \\\n",
       "0   4.4    n    y        ...                     1                0   \n",
       "1   4.4    n    y        ...                     1                0   \n",
       "2   4.4    n    y        ...                     1                1   \n",
       "3   4.4    n    y        ...                     1                0   \n",
       "4   4.4    n    y        ...                     1                0   \n",
       "\n",
       "  Number_of_Semicolons Number_of_Colons  Average_Word_Length  \\\n",
       "0                    0                0                4.400   \n",
       "1                    0                0                3.615   \n",
       "2                    0                0                3.500   \n",
       "3                    0                0                3.667   \n",
       "4                    0                0                2.333   \n",
       "\n",
       "   Lexical_Diversity  Number_of_FunctionalWords  Number_of_Pronouns  \\\n",
       "0              0.700                          2                   0   \n",
       "1              0.577                         10                   1   \n",
       "2              0.509                         14                   1   \n",
       "3              0.611                          4                   0   \n",
       "4              0.857                          1                   0   \n",
       "\n",
       "   Number_of_PROPNAMEs  SentimentNumeric  \n",
       "0                    0                 2  \n",
       "1                    0                 0  \n",
       "2                    0                 1  \n",
       "3                    0                 2  \n",
       "4                    0                 2  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_n = pd.read_csv(\"../raw_data/data_n.csv\", parse_dates=True, infer_datetime_format=True)\n",
    "data_n.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace 'y' and 'n'   AND easy split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>#AUTHID</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>sEXT</th>\n",
       "      <th>sNEU</th>\n",
       "      <th>sAGR</th>\n",
       "      <th>sCON</th>\n",
       "      <th>sOPN</th>\n",
       "      <th>cEXT</th>\n",
       "      <th>cNEU</th>\n",
       "      <th>...</th>\n",
       "      <th>Number_of_Dots</th>\n",
       "      <th>Number_of_Commas</th>\n",
       "      <th>Number_of_Semicolons</th>\n",
       "      <th>Number_of_Colons</th>\n",
       "      <th>Average_Word_Length</th>\n",
       "      <th>Lexical_Diversity</th>\n",
       "      <th>Number_of_FunctionalWords</th>\n",
       "      <th>Number_of_Pronouns</th>\n",
       "      <th>Number_of_PROPNAMEs</th>\n",
       "      <th>SentimentNumeric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
       "      <td>likes the sound of thunder.</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                           #AUTHID                       STATUS  \\\n",
       "0           1  b7b7764cfa1c523e4e93ab2a79a946c4  likes the sound of thunder.   \n",
       "\n",
       "   sEXT  sNEU  sAGR  sCON  sOPN  cEXT  cNEU        ...         Number_of_Dots  \\\n",
       "0  2.65     3  3.15  3.25   4.4     0     1        ...                      1   \n",
       "\n",
       "   Number_of_Commas  Number_of_Semicolons Number_of_Colons  \\\n",
       "0                 0                     0                0   \n",
       "\n",
       "   Average_Word_Length  Lexical_Diversity  Number_of_FunctionalWords  \\\n",
       "0                  4.4                0.7                          2   \n",
       "\n",
       "   Number_of_Pronouns  Number_of_PROPNAMEs  SentimentNumeric  \n",
       "0                   0                    0                 2  \n",
       "\n",
       "[1 rows x 33 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# http://stackoverflow.com/a/17702781\n",
    "d = {'n': 0, 'y': 1} # 1, y, = TRUE             0, n = FALSE\n",
    "data_n = data_n.replace(d)\n",
    "data_n.head(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#norm:http://blog.yhat.com/posts/predicting-customer-churn-with-sklearn.html\n",
    "# scaler = StandardScaler()\n",
    "# X = scaler.fit_transform(X)\n",
    "# to_drop = ['State','Area Code','Phone','Churn?']\n",
    "# churn_feat_space = data_n.drop(to_drop,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neu = data_n[[\"#AUTHID\",\"STATUS\",\"cNEU\",\"StringLength\", \n",
    "                  \"Number_of_Words\", \"Number_of_Dots\", \"Number_of_Commas\", \"Number_of_Semicolons\", \n",
    "                  \"Number_of_Colons\", \"Average_Word_Length\", \"Lexical_Diversity\", \"Number_of_FunctionalWords\", \"Number_of_Pronouns\", \"Number_of_PROPNAMEs\", \"SentimentNumeric\"]]\n",
    "ext = data_n[[\"#AUTHID\",\"STATUS\",\"cEXT\", \"StringLength\", \n",
    "                  \"Number_of_Words\", \"Number_of_Dots\", \"Number_of_Commas\", \"Number_of_Semicolons\", \n",
    "                  \"Number_of_Colons\", \"Average_Word_Length\", \"Lexical_Diversity\", \"Number_of_FunctionalWords\", \"Number_of_Pronouns\", \"Number_of_PROPNAMEs\", \"SentimentNumeric\"]]\n",
    "agr = data_n[[\"#AUTHID\",\"STATUS\",\"cAGR\",\"StringLength\", \n",
    "                  \"Number_of_Words\", \"Number_of_Dots\", \"Number_of_Commas\", \"Number_of_Semicolons\", \n",
    "                  \"Number_of_Colons\", \"Average_Word_Length\", \"Lexical_Diversity\", \"Number_of_FunctionalWords\", \"Number_of_Pronouns\", \"Number_of_PROPNAMEs\", \"SentimentNumeric\"]]\n",
    "con = data_n[[\"#AUTHID\",\"STATUS\",\"cCON\",\"StringLength\", \n",
    "                  \"Number_of_Words\", \"Number_of_Dots\", \"Number_of_Commas\", \"Number_of_Semicolons\", \n",
    "                  \"Number_of_Colons\", \"Average_Word_Length\", \"Lexical_Diversity\", \"Number_of_FunctionalWords\", \"Number_of_Pronouns\", \"Number_of_PROPNAMEs\", \"SentimentNumeric\"]]\n",
    "opn = data_n[[\"#AUTHID\",\"STATUS\",\"cOPN\", \"StringLength\", \n",
    "                  \"Number_of_Words\", \"Number_of_Dots\", \"Number_of_Commas\", \"Number_of_Semicolons\", \n",
    "                  \"Number_of_Colons\", \"Average_Word_Length\", \"Lexical_Diversity\", \"Number_of_FunctionalWords\", \"Number_of_Pronouns\", \"Number_of_PROPNAMEs\", \"SentimentNumeric\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split stratified k-folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# neu = data_n[[\"#AUTHID\",\"STATUS\",\"cNEU\"]]\n",
    "# train_neu, test_neu, y_train, y_test = sk.cross_validation.train_test_split(neu, neu[\"cNEU\"], train_size = 0.66, stratify= neu[\"cNEU\"])\n",
    "# train_neu, test_neu, y_train, y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6545, 15) (3372, 15) (6545,) (3372,)\n"
     ]
    }
   ],
   "source": [
    "train_feat_neu, test_feat_neu, train_class_neu, test_class_neu = sk.cross_validation.train_test_split(neu, neu[\"cNEU\"], train_size = 0.66, stratify = neu[\"cNEU\"],random_state= 5152)\n",
    "print(train_feat_neu.shape, test_feat_neu.shape,train_class_neu.shape ,test_class_neu.shape)\n",
    "\n",
    "neu_X = train_feat_neu.append(test_feat_neu)\n",
    "neu_Y = train_class_neu.append(test_class_neu)\n",
    "\n",
    "train_feat_ext, test_feat_ext, train_class_ext, test_class_ext = sk.cross_validation.train_test_split(ext, ext[\"cEXT\"], train_size = 0.66, stratify = ext[\"cEXT\"],random_state= 5152)\n",
    "\n",
    "ext_X = train_feat_ext.append(test_feat_ext)\n",
    "ext_Y = train_class_ext.append(test_class_ext)\n",
    "\n",
    "train_feat_agr, test_feat_agr, train_class_agr, test_class_agr = sk.cross_validation.train_test_split(agr, agr[\"cAGR\"], train_size = 0.66, stratify = agr[\"cAGR\"],random_state= 5152)\n",
    "\n",
    "agr_X = train_feat_agr.append(test_feat_agr)\n",
    "agr_Y = train_class_agr.append(test_class_agr)\n",
    "\n",
    "train_feat_con, test_feat_con, train_class_con, test_class_con = sk.cross_validation.train_test_split(con, con[\"cCON\"], train_size = 0.66, stratify = con[\"cCON\"],random_state= 5152)\n",
    "\n",
    "con_X = train_feat_con.append(test_feat_con)\n",
    "con_Y = train_class_con.append(test_class_con)\n",
    "\n",
    "train_feat_opn, test_feat_opn, train_class_opn, test_class_opn = sk.cross_validation.train_test_split(opn, opn[\"cOPN\"], train_size = 0.66, stratify = opn[\"cOPN\"],random_state= 5152)\n",
    "\n",
    "opn_X = train_feat_opn.append(test_feat_opn)\n",
    "opn_Y = train_class_opn.append(test_class_opn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_class_ext.to_csv(\"/home/jm/Documents/caseSolvingSeminar/raw_data/test_class_labels/ext_test.csv\",  header=None,  encoding=\"utf-8\")\n",
    "test_class_neu.to_csv(\"/home/jm/Documents/caseSolvingSeminar/raw_data/test_class_labels/neu_test.csv\",  header=None,  encoding=\"utf-8\")\n",
    "test_class_agr.to_csv(\"/home/jm/Documents/caseSolvingSeminar/raw_data/test_class_labels/agr_test.csv\",  header=None,  encoding=\"utf-8\")\n",
    "test_class_con.to_csv(\"/home/jm/Documents/caseSolvingSeminar/raw_data/test_class_labels/con_test.csv\",  header=None,  encoding=\"utf-8\")\n",
    "test_class_opn.to_csv(\"/home/jm/Documents/caseSolvingSeminar/raw_data/test_class_labels/opn_test.csv\",  header=None,  encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "skf_neu = StratifiedKFold(neu[\"cNEU\"], n_folds=10, shuffle=True, random_state = 5152)\n",
    "skf_ext = StratifiedKFold(ext[\"cEXT\"], n_folds=10, shuffle=True, random_state = 5152)\n",
    "skf_agr = StratifiedKFold(agr[\"cAGR\"], n_folds=10, shuffle=True, random_state = 5152)\n",
    "skf_con = StratifiedKFold(con[\"cCON\"], n_folds=10, shuffle=True, random_state = 5152)\n",
    "skf_opn = StratifiedKFold(opn[\"cOPN\"], n_folds=10, shuffle=True, random_state = 5152)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of classifiers \n",
    "with their configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nick_names = [\"tt SVC\", \"tt Linear SVC\", \"tt MultinomiaNB\", \"tt BernoulliNB\", \"ttRF\", \"ttAD\", \"ttKNN\"]\n",
    "classifiers = [\n",
    "    SVC(cache_size=500, kernel = \"rbf\", decision_function_shape = \"ovr\", random_state = 5152),\n",
    "    LinearSVC(random_state = 5152),\n",
    "    MultinomialNB(),\n",
    "    BernoulliNB(),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1, n_jobs=-1, random_state = 5152),\n",
    "    AdaBoostClassifier(random_state = 5152),\n",
    "    KNeighborsClassifier()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train + Test NEU\n",
    "\n",
    "read: https://stackoverflow.com/questions/31421413/how-to-compute-precision-recall-accuracy-and-f1-score-for-the-multiclass-case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FOR: tt SVC\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.94      0.75      2108\n",
      "          1       0.35      0.05      0.09      1264\n",
      "\n",
      "avg / total       0.52      0.61      0.50      3372\n",
      "\n",
      "[[1984  124]\n",
      " [1196   68]]\n",
      "F1:  0.0934065934066\n",
      "Precision:  0.381324890761\n",
      "Recall:  0.0537974683544\n",
      "Accuracy: 0.616 (+/- 0.03) [tt SVC]\n",
      "Accuracy score:  0.608540925267\n",
      "\n",
      "FOR: tt Linear SVC\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.03      0.05      2108\n",
      "          1       0.37      0.97      0.54      1264\n",
      "\n",
      "avg / total       0.50      0.38      0.23      3372\n",
      "\n",
      "[[  54 2054]\n",
      " [  40 1224]]\n",
      "F1:  0.538969616909\n",
      "Precision:  0.676807620125\n",
      "Recall:  0.96835443038\n",
      "Accuracy: 0.494 (+/- 0.25) [tt Linear SVC]\n",
      "Accuracy score:  0.379003558719\n",
      "\n",
      "FOR: tt MultinomiaNB\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.99      0.77      2108\n",
      "          1       0.48      0.01      0.02      1264\n",
      "\n",
      "avg / total       0.57      0.62      0.49      3372\n",
      "\n",
      "[[2094   14]\n",
      " [1251   13]]\n",
      "F1:  0.0201394268009\n",
      "Precision:  0.431381366445\n",
      "Recall:  0.0102848101266\n",
      "Accuracy: 0.624 (+/- 0.02) [tt MultinomiaNB]\n",
      "Accuracy score:  0.624851720047\n",
      "\n",
      "FOR: tt BernoulliNB\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      1.00      0.77      2108\n",
      "          1       0.40      0.00      0.01      1264\n",
      "\n",
      "avg / total       0.54      0.62      0.48      3372\n",
      "\n",
      "[[2102    6]\n",
      " [1260    4]]\n",
      "F1:  0.00627943485086\n",
      "Precision:  0.388415018695\n",
      "Recall:  0.00316455696203\n",
      "Accuracy: 0.625 (+/- 0.02) [tt BernoulliNB]\n",
      "Accuracy score:  0.624555160142\n",
      "\n",
      "FOR: ttRF\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      1.00      0.77      2108\n",
      "          1       0.53      0.01      0.01      1264\n",
      "\n",
      "avg / total       0.59      0.63      0.49      3372\n",
      "\n",
      "[[2100    8]\n",
      " [1255    9]]\n",
      "F1:  0.0140515222482\n",
      "Precision:  0.454357349386\n",
      "Recall:  0.00712025316456\n",
      "Accuracy: 0.625 (+/- 0.02) [ttRF]\n",
      "Accuracy score:  0.625444839858\n",
      "\n",
      "FOR: ttAD\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.98      0.76      2108\n",
      "          1       0.41      0.03      0.05      1264\n",
      "\n",
      "avg / total       0.55      0.62      0.50      3372\n",
      "\n",
      "[[2057   51]\n",
      " [1228   36]]\n",
      "F1:  0.0532938564027\n",
      "Precision:  0.403224839785\n",
      "Recall:  0.0284810126582\n",
      "Accuracy: 0.621 (+/- 0.02) [ttAD]\n",
      "Accuracy score:  0.620699881376\n",
      "\n",
      "FOR: ttKNN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.73      0.67      2108\n",
      "          1       0.36      0.25      0.30      1264\n",
      "\n",
      "avg / total       0.52      0.55      0.53      3372\n",
      "\n",
      "[[1539  569]\n",
      " [ 943  321]]\n",
      "F1:  0.298050139276\n",
      "Precision:  0.447142922008\n",
      "Recall:  0.253955696203\n",
      "Accuracy: 0.559 (+/- 0.03) [ttKNN]\n",
      "Accuracy score:  0.551601423488\n"
     ]
    }
   ],
   "source": [
    "# print(classifiers, nick_names)\n",
    "for name, clf in zip(nick_names, classifiers):\n",
    "    clf.fit(train_feat_neu[[\"StringLength\", \n",
    "                  \"Number_of_Words\", \"Number_of_Dots\", \"Number_of_Commas\", \"Number_of_Semicolons\", \n",
    "                  \"Number_of_Colons\", \"Average_Word_Length\", \"Lexical_Diversity\", \"Number_of_FunctionalWords\", \"Number_of_Pronouns\", \"Number_of_PROPNAMEs\", \"SentimentNumeric\"]], train_class_neu)\n",
    "    y_pred_neu = clf.predict(test_feat_neu[[\"StringLength\", \n",
    "                  \"Number_of_Words\", \"Number_of_Dots\", \"Number_of_Commas\", \"Number_of_Semicolons\", \n",
    "                  \"Number_of_Colons\", \"Average_Word_Length\", \"Lexical_Diversity\", \"Number_of_FunctionalWords\", \"Number_of_Pronouns\", \"Number_of_PROPNAMEs\", \"SentimentNumeric\"]])\n",
    "    print(\"\\nFOR:\", name)\n",
    "    print(sk.metrics.classification_report(test_class_neu, y_pred_neu, labels=[0, 1], target_names=[\"0\", \"1\"]))\n",
    "    print(sk.metrics.confusion_matrix(test_class_neu, y_pred_neu, labels=[0, 1]))\n",
    "    print(\"F1: \", sk.metrics.f1_score(test_class_neu, y_pred_neu, labels=[0, 1], average='binary'))\n",
    "    print(\"Precision: \", sk.metrics.average_precision_score(test_class_neu, y_pred_neu, average='micro'))\n",
    "    print(\"Recall: \", sk.metrics.recall_score(test_class_neu, y_pred_neu, labels=[0, 1], average='binary'))\n",
    "\n",
    "    np.savetxt(\"/home/jm/Documents/caseSolvingSeminar/raw_data/y_pred_class_labels/neu_pred\" + name + \".csv\", y_pred_neu, delimiter=\",\", fmt='%1.0f')\n",
    "    \n",
    "    scores = sk.cross_validation.cross_val_score(clf, neu_X[[\"StringLength\", \n",
    "                  \"Number_of_Words\", \"Number_of_Dots\", \"Number_of_Commas\", \"Number_of_Semicolons\", \n",
    "                  \"Number_of_Colons\", \"Average_Word_Length\", \"Lexical_Diversity\", \"Number_of_FunctionalWords\", \"Number_of_Pronouns\", \"Number_of_PROPNAMEs\", \"SentimentNumeric\"]], neu_Y, cv=skf_neu, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.3f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std()*2, name))\n",
    "    print(\"Accuracy score: \", sk.metrics.accuracy_score(test_class_neu, y_pred_neu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ttSVC' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-15f83439b000>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m eclf = VotingClassifier(estimators=[\n\u001b[1;32m----> 2\u001b[1;33m         \u001b[1;33m(\u001b[0m\u001b[1;34m\"svc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mttSVC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m         (\"linear_svc\", ttLinearSVC)], voting='hard')\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ttSVC' is not defined"
     ]
    }
   ],
   "source": [
    "eclf = VotingClassifier(estimators=[\n",
    "        (\"svc\", ttSVC),\n",
    "        (\"linear_svc\", ttLinearSVC)], voting='hard')\n",
    "\n",
    "\n",
    "for clf, label in zip([ttSVC, ttLinearSVC], [\"SVC\", \"LSVC\"]):\n",
    "    scores = cross_validation.cross_val_score(clf, neu_X[[\"StringLength\", \n",
    "                  \"Number_of_Words\", \"Number_of_Dots\", \"Number_of_Commas\", \"Number_of_Semicolons\", \n",
    "                  \"Number_of_Colons\", \"Average_Word_Length\", \"Lexical_Diversity\"]], neu_Y, cv=skf, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.3f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std()*2, label))\n",
    "    print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train + Test EXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FOR: tt SVC\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.86      0.70      1941\n",
      "          1       0.47      0.17      0.25      1431\n",
      "\n",
      "avg / total       0.54      0.57      0.51      3372\n",
      "\n",
      "[[1673  268]\n",
      " [1190  241]]\n",
      "F1:  0.248453608247\n",
      "Precision:  0.497398695233\n",
      "Recall:  0.168413696716\n",
      "Accuracy: 0.567 (+/- 0.03) [tt SVC]\n",
      "Accuracy score:  0.567615658363\n",
      "\n",
      "FOR: tt Linear SVC\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      1.00      0.73      1941\n",
      "          1       0.00      0.00      0.00      1431\n",
      "\n",
      "avg / total       0.33      0.58      0.42      3372\n",
      "\n",
      "[[1941    0]\n",
      " [1431    0]]\n",
      "F1:  0.0\n",
      "Precision:  0.7121886121\n",
      "Recall:  0.0\n",
      "Accuracy: 0.497 (+/- 0.13) [tt Linear SVC]\n",
      "Accuracy score:  0.575622775801\n",
      "\n",
      "FOR: tt MultinomiaNB\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.98      0.73      1941\n",
      "          1       0.58      0.04      0.08      1431\n",
      "\n",
      "avg / total       0.58      0.58      0.45      3372\n",
      "\n",
      "[[1898   43]\n",
      " [1372   59]]\n",
      "F1:  0.0769732550554\n",
      "Precision:  0.513270735751\n",
      "Recall:  0.0412299091544\n",
      "Accuracy: 0.578 (+/- 0.03) [tt MultinomiaNB]\n",
      "Accuracy score:  0.580367734282\n",
      "\n",
      "FOR: tt BernoulliNB\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.93      0.72      1941\n",
      "          1       0.56      0.12      0.20      1431\n",
      "\n",
      "avg / total       0.58      0.59      0.50      3372\n",
      "\n",
      "[[1802  139]\n",
      " [1257  174]]\n",
      "F1:  0.199541284404\n",
      "Precision:  0.525139817624\n",
      "Recall:  0.121593291405\n",
      "Accuracy: 0.580 (+/- 0.03) [tt BernoulliNB]\n",
      "Accuracy score:  0.586002372479\n",
      "\n",
      "FOR: ttRF\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.99      0.73      1941\n",
      "          1       0.70      0.05      0.09      1431\n",
      "\n",
      "avg / total       0.63      0.59      0.46      3372\n",
      "\n",
      "[[1912   29]\n",
      " [1362   69]]\n",
      "F1:  0.0902550686723\n",
      "Precision:  0.578107126375\n",
      "Recall:  0.0482180293501\n",
      "Accuracy: 0.579 (+/- 0.03) [ttRF]\n",
      "Accuracy score:  0.587485172005\n",
      "\n",
      "FOR: ttAD\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.91      0.72      1941\n",
      "          1       0.55      0.15      0.23      1431\n",
      "\n",
      "avg / total       0.57      0.59      0.51      3372\n",
      "\n",
      "[[1763  178]\n",
      " [1217  214]]\n",
      "F1:  0.234777838727\n",
      "Precision:  0.528188772021\n",
      "Recall:  0.149545772187\n",
      "Accuracy: 0.579 (+/- 0.03) [ttAD]\n",
      "Accuracy score:  0.586298932384\n",
      "\n",
      "FOR: ttKNN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.65      0.62      1941\n",
      "          1       0.44      0.38      0.41      1431\n",
      "\n",
      "avg / total       0.53      0.53      0.53      3372\n",
      "\n",
      "[[1254  687]\n",
      " [ 882  549]]\n",
      "F1:  0.411698537683\n",
      "Precision:  0.544694196161\n",
      "Recall:  0.383647798742\n",
      "Accuracy: 0.527 (+/- 0.02) [ttKNN]\n",
      "Accuracy score:  0.534697508897\n"
     ]
    }
   ],
   "source": [
    "# print(classifiers, nick_names)\n",
    "for name, clf in zip(nick_names, classifiers):\n",
    "    clf.fit(train_feat_ext[[\"StringLength\", \n",
    "                  \"Number_of_Words\", \"Number_of_Dots\", \"Number_of_Commas\", \"Number_of_Semicolons\", \n",
    "                  \"Number_of_Colons\", \"Average_Word_Length\", \"Lexical_Diversity\", \"Number_of_FunctionalWords\", \"Number_of_Pronouns\", \"Number_of_PROPNAMEs\", \"SentimentNumeric\"]], train_class_ext)\n",
    "    y_pred_ext = clf.predict(test_feat_ext[[\"StringLength\", \n",
    "                  \"Number_of_Words\", \"Number_of_Dots\", \"Number_of_Commas\", \"Number_of_Semicolons\", \n",
    "                  \"Number_of_Colons\", \"Average_Word_Length\", \"Lexical_Diversity\", \"Number_of_FunctionalWords\", \"Number_of_Pronouns\", \"Number_of_PROPNAMEs\", \"SentimentNumeric\"]])\n",
    "    print(\"\\nFOR:\", name)\n",
    "    print(sk.metrics.classification_report(test_class_ext, y_pred_ext, labels=[0, 1], target_names=[\"0\", \"1\"]))\n",
    "    print(sk.metrics.confusion_matrix(test_class_ext, y_pred_ext, labels=[0, 1]))\n",
    "    print(\"F1: \", sk.metrics.f1_score(test_class_ext, y_pred_ext, labels=[0, 1], average='binary'))\n",
    "    print(\"Precision: \", sk.metrics.average_precision_score(test_class_ext, y_pred_ext, average='micro'))\n",
    "    print(\"Recall: \", sk.metrics.recall_score(test_class_ext, y_pred_ext, labels=[0, 1], average='binary'))\n",
    "\n",
    "    np.savetxt(\"/home/jm/Documents/caseSolvingSeminar/raw_data/y_pred_class_labels/ext_pred\" + name + \".csv\", y_pred_ext, delimiter=\",\", fmt='%1.0f')\n",
    "    \n",
    "    scores = sk.cross_validation.cross_val_score(clf, ext_X[[\"StringLength\", \n",
    "                  \"Number_of_Words\", \"Number_of_Dots\", \"Number_of_Commas\", \"Number_of_Semicolons\", \n",
    "                  \"Number_of_Colons\", \"Average_Word_Length\", \"Lexical_Diversity\", \"Number_of_FunctionalWords\", \"Number_of_Pronouns\", \"Number_of_PROPNAMEs\", \"SentimentNumeric\"]], ext_Y, cv=skf_ext, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.3f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std()*2, name))\n",
    "    print(\"Accuracy score: \", sk.metrics.accuracy_score(test_class_ext, y_pred_ext))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train + Test CON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FOR: tt SVC\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.71      0.62      1823\n",
      "          1       0.49      0.32      0.39      1549\n",
      "\n",
      "avg / total       0.52      0.53      0.52      3372\n",
      "\n",
      "[[1303  520]\n",
      " [1049  500]]\n",
      "F1:  0.389256520047\n",
      "Precision:  0.562038157472\n",
      "Recall:  0.322788896062\n",
      "Accuracy: 0.532 (+/- 0.02) [tt SVC]\n",
      "Accuracy score:  0.534697508897\n",
      "\n",
      "FOR: tt Linear SVC\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.00      0.01      1823\n",
      "          1       0.46      1.00      0.63      1549\n",
      "\n",
      "avg / total       0.52      0.46      0.29      3372\n",
      "\n",
      "[[   8 1815]\n",
      " [   6 1543]]\n",
      "F1:  0.628897493377\n",
      "Precision:  0.728702797441\n",
      "Recall:  0.996126533247\n",
      "Accuracy: 0.515 (+/- 0.08) [tt Linear SVC]\n",
      "Accuracy score:  0.459964412811\n",
      "\n",
      "FOR: tt MultinomiaNB\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.81      0.65      1823\n",
      "          1       0.49      0.21      0.30      1549\n",
      "\n",
      "avg / total       0.52      0.54      0.49      3372\n",
      "\n",
      "[[1476  347]\n",
      " [1220  329]]\n",
      "F1:  0.295730337079\n",
      "Precision:  0.530442284182\n",
      "Recall:  0.212395093609\n",
      "Accuracy: 0.532 (+/- 0.03) [tt MultinomiaNB]\n",
      "Accuracy score:  0.535290628707\n",
      "\n",
      "FOR: tt BernoulliNB\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.77      0.65      1823\n",
      "          1       0.50      0.27      0.35      1549\n",
      "\n",
      "avg / total       0.53      0.54      0.51      3372\n",
      "\n",
      "[[1411  412]\n",
      " [1131  418]]\n",
      "F1:  0.351408154687\n",
      "Precision:  0.554437613804\n",
      "Recall:  0.269851517108\n",
      "Accuracy: 0.542 (+/- 0.04) [tt BernoulliNB]\n",
      "Accuracy score:  0.542408066429\n",
      "\n",
      "FOR: ttRF\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.94      0.69      1823\n",
      "          1       0.46      0.06      0.10      1549\n",
      "\n",
      "avg / total       0.50      0.54      0.42      3372\n",
      "\n",
      "[[1720  103]\n",
      " [1461   88]]\n",
      "F1:  0.101149425287\n",
      "Precision:  0.475408925676\n",
      "Recall:  0.0568108457069\n",
      "Accuracy: 0.547 (+/- 0.03) [ttRF]\n",
      "Accuracy score:  0.536180308422\n",
      "\n",
      "FOR: ttAD\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.82      0.66      1823\n",
      "          1       0.51      0.22      0.31      1549\n",
      "\n",
      "avg / total       0.53      0.54      0.50      3372\n",
      "\n",
      "[[1492  331]\n",
      " [1208  341]]\n",
      "F1:  0.307068887888\n",
      "Precision:  0.542913434333\n",
      "Recall:  0.220142027114\n",
      "Accuracy: 0.542 (+/- 0.03) [ttAD]\n",
      "Accuracy score:  0.54359430605\n",
      "\n",
      "FOR: ttKNN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.61      0.59      1823\n",
      "          1       0.49      0.44      0.47      1549\n",
      "\n",
      "avg / total       0.53      0.54      0.53      3372\n",
      "\n",
      "[[1118  705]\n",
      " [ 862  687]]\n",
      "F1:  0.467188031282\n",
      "Precision:  0.596340532072\n",
      "Recall:  0.443511943189\n",
      "Accuracy: 0.522 (+/- 0.03) [ttKNN]\n",
      "Accuracy score:  0.535290628707\n"
     ]
    }
   ],
   "source": [
    "# print(classifiers, nick_names)\n",
    "for name, clf in zip(nick_names, classifiers):\n",
    "    clf.fit(train_feat_con[[\"StringLength\", \n",
    "                  \"Number_of_Words\", \"Number_of_Dots\", \"Number_of_Commas\", \"Number_of_Semicolons\", \n",
    "                  \"Number_of_Colons\", \"Average_Word_Length\", \"Lexical_Diversity\", \"Number_of_FunctionalWords\", \"Number_of_Pronouns\", \"Number_of_PROPNAMEs\", \"SentimentNumeric\"]], train_class_con)\n",
    "    y_pred_con = clf.predict(test_feat_con[[\"StringLength\", \n",
    "                  \"Number_of_Words\", \"Number_of_Dots\", \"Number_of_Commas\", \"Number_of_Semicolons\", \n",
    "                  \"Number_of_Colons\", \"Average_Word_Length\", \"Lexical_Diversity\", \"Number_of_FunctionalWords\", \"Number_of_Pronouns\", \"Number_of_PROPNAMEs\", \"SentimentNumeric\"]])\n",
    "    print(\"\\nFOR:\", name)\n",
    "    print(sk.metrics.classification_report(test_class_con, y_pred_con, labels=[0, 1], target_names=[\"0\", \"1\"]))\n",
    "    print(sk.metrics.confusion_matrix(test_class_con, y_pred_con, labels=[0, 1]))\n",
    "    print(\"F1: \", sk.metrics.f1_score(test_class_con, y_pred_con, labels=[0, 1], average='binary'))\n",
    "    print(\"Precision: \", sk.metrics.average_precision_score(test_class_con, y_pred_con, average='micro'))\n",
    "    print(\"Recall: \", sk.metrics.recall_score(test_class_con, y_pred_con, labels=[0, 1], average='binary'))\n",
    "\n",
    "    np.savetxt(\"/home/jm/Documents/caseSolvingSeminar/raw_data/y_pred_class_labels/con_pred\" + name + \".csv\", y_pred_con, delimiter=\",\", fmt='%1.0f')\n",
    "    \n",
    "    scores = sk.cross_validation.cross_val_score(clf, con_X[[\"StringLength\", \n",
    "                  \"Number_of_Words\", \"Number_of_Dots\", \"Number_of_Commas\", \"Number_of_Semicolons\", \n",
    "                  \"Number_of_Colons\", \"Average_Word_Length\", \"Lexical_Diversity\", \"Number_of_FunctionalWords\", \"Number_of_Pronouns\", \"Number_of_PROPNAMEs\", \"SentimentNumeric\"]], con_Y, cv=skf_con, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.3f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std()*2, name))\n",
    "    print(\"Accuracy score: \", sk.metrics.accuracy_score(test_class_con, y_pred_con))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train + Test AGR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FOR: tt SVC\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.49      0.34      0.40      1581\n",
      "          1       0.54      0.68      0.60      1791\n",
      "\n",
      "avg / total       0.51      0.52      0.51      3372\n",
      "\n",
      "[[ 545 1036]\n",
      " [ 578 1213]]\n",
      "F1:  0.600495049505\n",
      "Precision:  0.694018856476\n",
      "Recall:  0.677275265215\n",
      "Accuracy: 0.514 (+/- 0.02) [tt SVC]\n",
      "Accuracy score:  0.521352313167\n",
      "\n",
      "FOR: tt Linear SVC\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.01      0.02      1581\n",
      "          1       0.53      0.99      0.69      1791\n",
      "\n",
      "avg / total       0.53      0.53      0.38      3372\n",
      "\n",
      "[[  15 1566]\n",
      " [  13 1778]]\n",
      "F1:  0.692502434275\n",
      "Precision:  0.764147664282\n",
      "Recall:  0.992741485204\n",
      "Accuracy: 0.503 (+/- 0.07) [tt Linear SVC]\n",
      "Accuracy score:  0.531731909846\n",
      "\n",
      "FOR: tt MultinomiaNB\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.16      0.24      1581\n",
      "          1       0.54      0.88      0.67      1791\n",
      "\n",
      "avg / total       0.54      0.54      0.47      3372\n",
      "\n",
      "[[ 251 1330]\n",
      " [ 218 1573]]\n",
      "F1:  0.670217298679\n",
      "Precision:  0.742391802453\n",
      "Recall:  0.878280290341\n",
      "Accuracy: 0.527 (+/- 0.03) [tt MultinomiaNB]\n",
      "Accuracy score:  0.540925266904\n",
      "\n",
      "FOR: tt BernoulliNB\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.18      0.27      1581\n",
      "          1       0.55      0.87      0.67      1791\n",
      "\n",
      "avg / total       0.55      0.55      0.48      3372\n",
      "\n",
      "[[ 285 1296]\n",
      " [ 228 1563]]\n",
      "F1:  0.672258064516\n",
      "Precision:  0.743503562131\n",
      "Recall:  0.87269681742\n",
      "Accuracy: 0.538 (+/- 0.03) [tt BernoulliNB]\n",
      "Accuracy score:  0.548042704626\n",
      "\n",
      "FOR: ttRF\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.16      0.25      1581\n",
      "          1       0.54      0.89      0.67      1791\n",
      "\n",
      "avg / total       0.55      0.55      0.47      3372\n",
      "\n",
      "[[ 252 1329]\n",
      " [ 205 1586]]\n",
      "F1:  0.674033149171\n",
      "Precision:  0.745207959222\n",
      "Recall:  0.885538805137\n",
      "Accuracy: 0.539 (+/- 0.03) [ttRF]\n",
      "Accuracy score:  0.545077105575\n",
      "\n",
      "FOR: ttAD\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.34      0.41      1581\n",
      "          1       0.56      0.73      0.63      1791\n",
      "\n",
      "avg / total       0.54      0.55      0.53      3372\n",
      "\n",
      "[[ 532 1049]\n",
      " [ 481 1310]]\n",
      "F1:  0.631325301205\n",
      "Precision:  0.714700158881\n",
      "Recall:  0.73143495254\n",
      "Accuracy: 0.538 (+/- 0.02) [ttAD]\n",
      "Accuracy score:  0.546263345196\n",
      "\n",
      "FOR: ttKNN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.47      0.43      0.45      1581\n",
      "          1       0.53      0.56      0.55      1791\n",
      "\n",
      "avg / total       0.50      0.50      0.50      3372\n",
      "\n",
      "[[ 683  898]\n",
      " [ 782 1009]]\n",
      "F1:  0.545700378583\n",
      "Precision:  0.662192783525\n",
      "Recall:  0.563372417644\n",
      "Accuracy: 0.509 (+/- 0.02) [ttKNN]\n",
      "Accuracy score:  0.501779359431\n"
     ]
    }
   ],
   "source": [
    "# print(classifiers, nick_names)\n",
    "for name, clf in zip(nick_names, classifiers):\n",
    "    clf.fit(train_feat_agr[[\"StringLength\", \n",
    "                  \"Number_of_Words\", \"Number_of_Dots\", \"Number_of_Commas\", \"Number_of_Semicolons\", \n",
    "                  \"Number_of_Colons\", \"Average_Word_Length\", \"Lexical_Diversity\", \"Number_of_FunctionalWords\", \"Number_of_Pronouns\", \"Number_of_PROPNAMEs\", \"SentimentNumeric\"]], train_class_agr)\n",
    "    y_pred_agr = clf.predict(test_feat_agr[[\"StringLength\", \n",
    "                  \"Number_of_Words\", \"Number_of_Dots\", \"Number_of_Commas\", \"Number_of_Semicolons\", \n",
    "                  \"Number_of_Colons\", \"Average_Word_Length\", \"Lexical_Diversity\", \"Number_of_FunctionalWords\", \"Number_of_Pronouns\", \"Number_of_PROPNAMEs\", \"SentimentNumeric\"]])\n",
    "    print(\"\\nFOR:\", name)\n",
    "    print(sk.metrics.classification_report(test_class_agr, y_pred_agr, labels=[0, 1], target_names=[\"0\", \"1\"]))\n",
    "    print(sk.metrics.confusion_matrix(test_class_agr, y_pred_agr, labels=[0, 1]))\n",
    "    print(\"F1: \", sk.metrics.f1_score(test_class_agr, y_pred_agr, labels=[0, 1], average='binary'))\n",
    "    print(\"Precision: \", sk.metrics.average_precision_score(test_class_agr, y_pred_agr, average='micro'))\n",
    "    print(\"Recall: \", sk.metrics.recall_score(test_class_agr, y_pred_agr, labels=[0, 1], average='binary'))\n",
    "\n",
    "    np.savetxt(\"/home/jm/Documents/caseSolvingSeminar/raw_data/y_pred_class_labels/agr_pred\" + name + \".csv\", y_pred_agr, delimiter=\",\", fmt='%1.0f')\n",
    "    \n",
    "    scores = sk.cross_validation.cross_val_score(clf, agr_X[[\"StringLength\", \n",
    "                  \"Number_of_Words\", \"Number_of_Dots\", \"Number_of_Commas\", \"Number_of_Semicolons\", \n",
    "                  \"Number_of_Colons\", \"Average_Word_Length\", \"Lexical_Diversity\", \"Number_of_FunctionalWords\", \"Number_of_Pronouns\", \"Number_of_PROPNAMEs\", \"SentimentNumeric\"]], agr_Y, cv=skf_agr, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.3f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std()*2, name))\n",
    "    print(\"Accuracy score: \", sk.metrics.accuracy_score(test_class_agr, y_pred_agr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train + Test OPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FOR: tt SVC\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.42      0.01      0.01       866\n",
      "          1       0.74      1.00      0.85      2506\n",
      "\n",
      "avg / total       0.66      0.74      0.64      3372\n",
      "\n",
      "[[   5  861]\n",
      " [   7 2499]]\n",
      "F1:  0.852028639618\n",
      "Precision:  0.871516311623\n",
      "Recall:  0.997206703911\n",
      "Accuracy: 0.740 (+/- 0.02) [tt SVC]\n",
      "Accuracy score:  0.742586002372\n",
      "\n",
      "FOR: tt Linear SVC\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       866\n",
      "          1       0.74      1.00      0.85      2506\n",
      "\n",
      "avg / total       0.55      0.74      0.63      3372\n",
      "\n",
      "[[   0  866]\n",
      " [   0 2506]]\n",
      "F1:  0.852670976523\n",
      "Precision:  0.871589561091\n",
      "Recall:  1.0\n",
      "Accuracy: 0.660 (+/- 0.32) [tt Linear SVC]\n",
      "Accuracy score:  0.743179122183\n",
      "\n",
      "FOR: tt MultinomiaNB\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.02      0.03       866\n",
      "          1       0.75      1.00      0.85      2506\n",
      "\n",
      "avg / total       0.71      0.74      0.64      3372\n",
      "\n",
      "[[  13  853]\n",
      " [   8 2498]]\n",
      "F1:  0.852996414547\n",
      "Precision:  0.872314630259\n",
      "Recall:  0.996807661612\n",
      "Accuracy: 0.730 (+/- 0.03) [tt MultinomiaNB]\n",
      "Accuracy score:  0.744661921708\n",
      "\n",
      "FOR: tt BernoulliNB\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       866\n",
      "          1       0.74      1.00      0.85      2506\n",
      "\n",
      "avg / total       0.55      0.74      0.63      3372\n",
      "\n",
      "[[   0  866]\n",
      " [   0 2506]]\n",
      "F1:  0.852670976523\n",
      "Precision:  0.871589561091\n",
      "Recall:  1.0\n",
      "Accuracy: 0.743 (+/- 0.02) [tt BernoulliNB]\n",
      "Accuracy score:  0.743179122183\n",
      "\n",
      "FOR: ttRF\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.25      0.00      0.00       866\n",
      "          1       0.74      1.00      0.85      2506\n",
      "\n",
      "avg / total       0.62      0.74      0.63      3372\n",
      "\n",
      "[[   1  865]\n",
      " [   3 2503]]\n",
      "F1:  0.852230166837\n",
      "Precision:  0.871431787099\n",
      "Recall:  0.998802873105\n",
      "Accuracy: 0.743 (+/- 0.02) [ttRF]\n",
      "Accuracy score:  0.742586002372\n",
      "\n",
      "FOR: ttAD\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.41      0.01      0.02       866\n",
      "          1       0.74      0.99      0.85      2506\n",
      "\n",
      "avg / total       0.66      0.74      0.64      3372\n",
      "\n",
      "[[  11  855]\n",
      " [  16 2490]]\n",
      "F1:  0.851136557853\n",
      "Precision:  0.87137745027\n",
      "Recall:  0.993615323224\n",
      "Accuracy: 0.742 (+/- 0.03) [ttAD]\n",
      "Accuracy score:  0.741696322657\n",
      "\n",
      "FOR: ttKNN\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.28      0.13      0.18       866\n",
      "          1       0.75      0.89      0.81      2506\n",
      "\n",
      "avg / total       0.63      0.69      0.65      3372\n",
      "\n",
      "[[ 112  754]\n",
      " [ 287 2219]]\n",
      "F1:  0.810001825151\n",
      "Precision:  0.85848583844\n",
      "Recall:  0.885474860335\n",
      "Accuracy: 0.693 (+/- 0.03) [ttKNN]\n",
      "Accuracy score:  0.69128113879\n"
     ]
    }
   ],
   "source": [
    "# print(classifiers, nick_names)\n",
    "for name, clf in zip(nick_names, classifiers):\n",
    "    clf.fit(train_feat_opn[[\"StringLength\", \n",
    "                  \"Number_of_Words\", \"Number_of_Dots\", \"Number_of_Commas\", \"Number_of_Semicolons\", \n",
    "                  \"Number_of_Colons\", \"Average_Word_Length\", \"Lexical_Diversity\", \"Number_of_FunctionalWords\", \"Number_of_Pronouns\", \"Number_of_PROPNAMEs\", \"SentimentNumeric\"]], train_class_opn)\n",
    "    y_pred_opn = clf.predict(test_feat_opn[[\"StringLength\", \n",
    "                  \"Number_of_Words\", \"Number_of_Dots\", \"Number_of_Commas\", \"Number_of_Semicolons\", \n",
    "                  \"Number_of_Colons\", \"Average_Word_Length\", \"Lexical_Diversity\", \"Number_of_FunctionalWords\", \"Number_of_Pronouns\", \"Number_of_PROPNAMEs\", \"SentimentNumeric\"]])\n",
    "    print(\"\\nFOR:\", name)\n",
    "    print(sk.metrics.classification_report(test_class_opn, y_pred_opn, labels=[0, 1], target_names=[\"0\", \"1\"]))\n",
    "    print(sk.metrics.confusion_matrix(test_class_opn, y_pred_opn, labels=[0, 1]))\n",
    "    print(\"F1: \", sk.metrics.f1_score(test_class_opn, y_pred_opn, labels=[0, 1], average='binary'))\n",
    "    print(\"Precision: \", sk.metrics.average_precision_score(test_class_opn, y_pred_opn, average='micro'))\n",
    "    print(\"Recall: \", sk.metrics.recall_score(test_class_opn, y_pred_opn, labels=[0, 1], average='binary'))\n",
    "\n",
    "    np.savetxt(\"/home/jm/Documents/caseSolvingSeminar/raw_data/y_pred_class_labels/opn_pred\" + name + \".csv\", y_pred_opn, delimiter=\",\", fmt='%1.0f')\n",
    "    \n",
    "    scores = sk.cross_validation.cross_val_score(clf, opn_X[[\"StringLength\", \n",
    "                  \"Number_of_Words\", \"Number_of_Dots\", \"Number_of_Commas\", \"Number_of_Semicolons\", \n",
    "                  \"Number_of_Colons\", \"Average_Word_Length\", \"Lexical_Diversity\", \"Number_of_FunctionalWords\", \"Number_of_Pronouns\", \"Number_of_PROPNAMEs\", \"SentimentNumeric\"]], opn_Y, cv=skf_opn, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.3f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std()*2, name))\n",
    "    print(\"Accuracy score: \", sk.metrics.accuracy_score(test_class_opn, y_pred_opn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
